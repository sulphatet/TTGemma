{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "14e48e886ae64914b126f35fcc12dee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6278f391e9804e2998eddb81d0551eff",
              "IPY_MODEL_84e242e4c9ac4a91b3776407bb1a4a65",
              "IPY_MODEL_ddfc8fd67fc8481faf8aaa46b15fe930"
            ],
            "layout": "IPY_MODEL_dc829880b63a407a813d22552ec175be"
          }
        },
        "6278f391e9804e2998eddb81d0551eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e30bb8953b7242b5ad07a7817dd34d56",
            "placeholder": "​",
            "style": "IPY_MODEL_1edb2dc2f34a47fca76f9a1257c89a3d",
            "value": "Resolving data files: 100%"
          }
        },
        "84e242e4c9ac4a91b3776407bb1a4a65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_346c2b8b77af43ddbf421f7cb65a7312",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_60b0710d17d74451ad5481b81aa140a1",
            "value": 50
          }
        },
        "ddfc8fd67fc8481faf8aaa46b15fe930": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_93d221dab0ab45b98339d784d6d0fadc",
            "placeholder": "​",
            "style": "IPY_MODEL_2d5356d1f461474082e6ef5580a6f90d",
            "value": " 50/50 [00:00&lt;00:00, 3243.00it/s]"
          }
        },
        "dc829880b63a407a813d22552ec175be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e30bb8953b7242b5ad07a7817dd34d56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1edb2dc2f34a47fca76f9a1257c89a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "346c2b8b77af43ddbf421f7cb65a7312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b0710d17d74451ad5481b81aa140a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93d221dab0ab45b98339d784d6d0fadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d5356d1f461474082e6ef5580a6f90d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8862fa6c5d5b49b79fb46495e9772cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0231f2d8cff04d2e803f594cfb232e9b",
              "IPY_MODEL_e04b86e8e96d4ef4810bae5275f845ff",
              "IPY_MODEL_79bcd603d63f4f868b08506331374958"
            ],
            "layout": "IPY_MODEL_65abc79417ac40be9e50c807ac360117"
          }
        },
        "0231f2d8cff04d2e803f594cfb232e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_046cb18bb1d549c3b8a33e2224640d2d",
            "placeholder": "​",
            "style": "IPY_MODEL_b1068d0755a5445095782d393bae970a",
            "value": "Resolving data files: 100%"
          }
        },
        "e04b86e8e96d4ef4810bae5275f845ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bd01bc12d704cc98b80b33c8c62495c",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e332ef22dcfb495e8bc0dad79e0ebdc2",
            "value": 100
          }
        },
        "79bcd603d63f4f868b08506331374958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58351b97c3404c488a392bbd23ed9cdf",
            "placeholder": "​",
            "style": "IPY_MODEL_7169d43e4c4045e582c16c31f75360b5",
            "value": " 100/100 [00:00&lt;00:00, 83.46it/s]"
          }
        },
        "65abc79417ac40be9e50c807ac360117": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "046cb18bb1d549c3b8a33e2224640d2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1068d0755a5445095782d393bae970a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9bd01bc12d704cc98b80b33c8c62495c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e332ef22dcfb495e8bc0dad79e0ebdc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "58351b97c3404c488a392bbd23ed9cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7169d43e4c4045e582c16c31f75360b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c018fd74f4f34460aad1a83e9b598e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bf2b820935f4c2991669fbe75a3b8d4",
              "IPY_MODEL_77937364dd2c45178351d364e0fecba4",
              "IPY_MODEL_c42c44d57d9847728f37cfa3d0c05f67"
            ],
            "layout": "IPY_MODEL_c9c93e1794fd4eb79c91677d60a06d17"
          }
        },
        "3bf2b820935f4c2991669fbe75a3b8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0bfb5f942ab4edd90448d24d3a17ff6",
            "placeholder": "​",
            "style": "IPY_MODEL_84d7c649a01a4da9862529af930326a3",
            "value": "Resolving data files: 100%"
          }
        },
        "77937364dd2c45178351d364e0fecba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2673bbed820457bb09233ea8257389e",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bb2011fa9b7642e08414b4c60321d7f3",
            "value": 25
          }
        },
        "c42c44d57d9847728f37cfa3d0c05f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da53f77444fa42a0a8e407c59479d038",
            "placeholder": "​",
            "style": "IPY_MODEL_fc94876311a742f8940d6924c1d02d9f",
            "value": " 25/25 [00:00&lt;00:00, 1608.89it/s]"
          }
        },
        "c9c93e1794fd4eb79c91677d60a06d17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0bfb5f942ab4edd90448d24d3a17ff6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84d7c649a01a4da9862529af930326a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2673bbed820457bb09233ea8257389e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb2011fa9b7642e08414b4c60321d7f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da53f77444fa42a0a8e407c59479d038": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc94876311a742f8940d6924c1d02d9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3894b3bbe39e45a8a40ca38fc1fc7211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44f3aef0aa71412e9bcae5bf97c0bdc1",
              "IPY_MODEL_e396a1fd0dc84392b581ff55f7b753ef",
              "IPY_MODEL_e848cb1a040f4ba290a16ff3e6b30c1b"
            ],
            "layout": "IPY_MODEL_29d742b12a85410b87b09f0289c8b850"
          }
        },
        "44f3aef0aa71412e9bcae5bf97c0bdc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8e13502deb24af2a9a60c0ba47869d2",
            "placeholder": "​",
            "style": "IPY_MODEL_fec0fbb2b0c649eb81505e481ed9e3a9",
            "value": "Resolving data files: 100%"
          }
        },
        "e396a1fd0dc84392b581ff55f7b753ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f24abd870d4633b716af2a2acb9f13",
            "max": 50,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ba2c6c1fa4244fbb3296b811bdc5e27",
            "value": 50
          }
        },
        "e848cb1a040f4ba290a16ff3e6b30c1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b5c37a2b7d430dabaaac4bc2bfe754",
            "placeholder": "​",
            "style": "IPY_MODEL_39adae1c7e654c53a9d6ca722ce132e8",
            "value": " 50/50 [00:00&lt;00:00, 21.85it/s]"
          }
        },
        "29d742b12a85410b87b09f0289c8b850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8e13502deb24af2a9a60c0ba47869d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fec0fbb2b0c649eb81505e481ed9e3a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f24abd870d4633b716af2a2acb9f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba2c6c1fa4244fbb3296b811bdc5e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "25b5c37a2b7d430dabaaac4bc2bfe754": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39adae1c7e654c53a9d6ca722ce132e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e241844571854664b6a7cdd68004bd3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a2577ba01d314a88883e53108fe90378",
              "IPY_MODEL_1e279e6abbd24a6d91b9a6e3451c1e77",
              "IPY_MODEL_bc2c61f8ca044370b908f9c714ad2fa5"
            ],
            "layout": "IPY_MODEL_c58612d3ee864fe9a44092cc01b0fb21"
          }
        },
        "a2577ba01d314a88883e53108fe90378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d85755237d6244509a2bf6bbdfbc6604",
            "placeholder": "​",
            "style": "IPY_MODEL_24e4f58f2afa48e7983ff9a9bc049ecc",
            "value": "Resolving data files: 100%"
          }
        },
        "1e279e6abbd24a6d91b9a6e3451c1e77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71ddb8cfa9ec41a1ac18044685a7edcf",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b87215912034972b36f8dc50fe15d39",
            "value": 100
          }
        },
        "bc2c61f8ca044370b908f9c714ad2fa5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1bbe9cb0eaab48b4acb2c4fc3f99621d",
            "placeholder": "​",
            "style": "IPY_MODEL_dff5abf007104071bfc5db4d11acfdb9",
            "value": " 100/100 [00:01&lt;00:00,  1.15s/it]"
          }
        },
        "c58612d3ee864fe9a44092cc01b0fb21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d85755237d6244509a2bf6bbdfbc6604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "24e4f58f2afa48e7983ff9a9bc049ecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71ddb8cfa9ec41a1ac18044685a7edcf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b87215912034972b36f8dc50fe15d39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bbe9cb0eaab48b4acb2c4fc3f99621d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dff5abf007104071bfc5db4d11acfdb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd84386f85cc42e6b758c37bb77f4ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8729f623646046ea838dd855efc4e186",
              "IPY_MODEL_97eae876a4304c5a98d38ee4c24eaaa7",
              "IPY_MODEL_3cb14259464a47678bb161c7f09ee9f7"
            ],
            "layout": "IPY_MODEL_ea57494af6a144a099aafcef8057cdb5"
          }
        },
        "8729f623646046ea838dd855efc4e186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce1bdcf8264d407fbad092d91ce46ce4",
            "placeholder": "​",
            "style": "IPY_MODEL_6a463d8fe7274183a5119166710db309",
            "value": "Resolving data files: 100%"
          }
        },
        "97eae876a4304c5a98d38ee4c24eaaa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_efaaa106b98f421c82fb79f48882e7d7",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1961365df01546ba8557b39612a4e0b0",
            "value": 25
          }
        },
        "3cb14259464a47678bb161c7f09ee9f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44219b9f2c68494b9fbeba94b77a624c",
            "placeholder": "​",
            "style": "IPY_MODEL_f382ec6e9aff42f2a633f346624c8c81",
            "value": " 25/25 [00:00&lt;00:00, 1050.00it/s]"
          }
        },
        "ea57494af6a144a099aafcef8057cdb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce1bdcf8264d407fbad092d91ce46ce4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6a463d8fe7274183a5119166710db309": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "efaaa106b98f421c82fb79f48882e7d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1961365df01546ba8557b39612a4e0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44219b9f2c68494b9fbeba94b77a624c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f382ec6e9aff42f2a633f346624c8c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f521f378bab646b4a6147b708e0c7a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ba7f3c4592f4302b3460395ded7df4a",
              "IPY_MODEL_b79b19eb0de041cca9cc595f25161cb3",
              "IPY_MODEL_0a9539844a864837bdbf2166246daf64"
            ],
            "layout": "IPY_MODEL_84476289253e4205be60efe6d0f3c46e"
          }
        },
        "5ba7f3c4592f4302b3460395ded7df4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fb03458453a404fa407e2be9f840471",
            "placeholder": "​",
            "style": "IPY_MODEL_5d1a34ac1e53443f9eac07c0e6001d1c",
            "value": "README.md: "
          }
        },
        "b79b19eb0de041cca9cc595f25161cb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d1808baea4848bfb91aa4a05d50c688",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e1e0fe4a3614ff5901171e0da8d99ca",
            "value": 1
          }
        },
        "0a9539844a864837bdbf2166246daf64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4675ce886748e19fd2bb2a5aa81a9f",
            "placeholder": "​",
            "style": "IPY_MODEL_0b2eb7a1b18d41bc8e0840bee457a549",
            "value": " 10.9k/? [00:00&lt;00:00, 682kB/s]"
          }
        },
        "84476289253e4205be60efe6d0f3c46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fb03458453a404fa407e2be9f840471": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d1a34ac1e53443f9eac07c0e6001d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d1808baea4848bfb91aa4a05d50c688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7e1e0fe4a3614ff5901171e0da8d99ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e4675ce886748e19fd2bb2a5aa81a9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b2eb7a1b18d41bc8e0840bee457a549": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "adc935d341ea421a9f380a60cb77639a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0b5d203495a14ea6a6406d68a6568dad",
              "IPY_MODEL_5c0ac1cd31bf4133a872942723d5ac00",
              "IPY_MODEL_7427601ef0ee475d9afc752e9062cce9"
            ],
            "layout": "IPY_MODEL_e36924d4a056481cb6280a9339407f71"
          }
        },
        "0b5d203495a14ea6a6406d68a6568dad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b6f69b5576f456c82a556d92439211b",
            "placeholder": "​",
            "style": "IPY_MODEL_0f19ecef46c04cefb93b85577dea418c",
            "value": "Resolving data files: 100%"
          }
        },
        "5c0ac1cd31bf4133a872942723d5ac00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_105df3cf1ba84fc5972fa9bff47e3fb8",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_297e6387fab3404d8e2be32b1bad1ef3",
            "value": 25
          }
        },
        "7427601ef0ee475d9afc752e9062cce9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47772694d8d945b5ad7c953cbeb72974",
            "placeholder": "​",
            "style": "IPY_MODEL_2da011c8c2f44f209bf6af91cd37b181",
            "value": " 25/25 [00:00&lt;00:00,  6.85it/s]"
          }
        },
        "e36924d4a056481cb6280a9339407f71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b6f69b5576f456c82a556d92439211b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f19ecef46c04cefb93b85577dea418c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "105df3cf1ba84fc5972fa9bff47e3fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "297e6387fab3404d8e2be32b1bad1ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47772694d8d945b5ad7c953cbeb72974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da011c8c2f44f209bf6af91cd37b181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757,
          "referenced_widgets": [
            "14e48e886ae64914b126f35fcc12dee9",
            "6278f391e9804e2998eddb81d0551eff",
            "84e242e4c9ac4a91b3776407bb1a4a65",
            "ddfc8fd67fc8481faf8aaa46b15fe930",
            "dc829880b63a407a813d22552ec175be",
            "e30bb8953b7242b5ad07a7817dd34d56",
            "1edb2dc2f34a47fca76f9a1257c89a3d",
            "346c2b8b77af43ddbf421f7cb65a7312",
            "60b0710d17d74451ad5481b81aa140a1",
            "93d221dab0ab45b98339d784d6d0fadc",
            "2d5356d1f461474082e6ef5580a6f90d",
            "8862fa6c5d5b49b79fb46495e9772cf0",
            "0231f2d8cff04d2e803f594cfb232e9b",
            "e04b86e8e96d4ef4810bae5275f845ff",
            "79bcd603d63f4f868b08506331374958",
            "65abc79417ac40be9e50c807ac360117",
            "046cb18bb1d549c3b8a33e2224640d2d",
            "b1068d0755a5445095782d393bae970a",
            "9bd01bc12d704cc98b80b33c8c62495c",
            "e332ef22dcfb495e8bc0dad79e0ebdc2",
            "58351b97c3404c488a392bbd23ed9cdf",
            "7169d43e4c4045e582c16c31f75360b5",
            "c018fd74f4f34460aad1a83e9b598e8e",
            "3bf2b820935f4c2991669fbe75a3b8d4",
            "77937364dd2c45178351d364e0fecba4",
            "c42c44d57d9847728f37cfa3d0c05f67",
            "c9c93e1794fd4eb79c91677d60a06d17",
            "b0bfb5f942ab4edd90448d24d3a17ff6",
            "84d7c649a01a4da9862529af930326a3",
            "d2673bbed820457bb09233ea8257389e",
            "bb2011fa9b7642e08414b4c60321d7f3",
            "da53f77444fa42a0a8e407c59479d038",
            "fc94876311a742f8940d6924c1d02d9f"
          ]
        },
        "id": "CjY4Zv3i7xVf",
        "outputId": "77a24a3b-1b3c-4363-9fc9-6fcb86154d2a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installing required libraries...\n",
            "--> Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Output data will be saved to: /content/drive/My Drive/LMA_SLM/data/raw\n",
            "Reports will be saved to: /content/drive/My Drive/LMA_SLM/reports\n",
            "\n",
            "--> [dl] Streaming first 20,000 docs: ai4bharat/sangraha :: verified/eng\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "14e48e886ae64914b126f35fcc12dee9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Reached streaming limit of 20000 for verified/eng.\n",
            "--> [dl] Streaming first 20,000 docs: ai4bharat/sangraha :: published/eng\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not stream from published/eng. Error: The directory at hf://datasets/ai4bharat/sangraha@8b813c3f62d37b2fa174d68c31e8b35ae2fe85e8/published/eng doesn't contain any data files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[stats:eng] docs=20,000 | mean=2651.7 | p50=1,892.0 | max=261,788\n",
            "📊 Plot saved to /content/drive/My Drive/LMA_SLM/reports/download_stats_eng.png\n",
            "✅ Wrote 20,000 records to /content/drive/My Drive/LMA_SLM/data/raw/eng.jsonl\n",
            "--------------------------------------------------\n",
            "--> [dl] Streaming first 20,000 docs: ai4bharat/sangraha :: verified/hin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8862fa6c5d5b49b79fb46495e9772cf0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Reached streaming limit of 20000 for verified/hin.\n",
            "--> [dl] Streaming first 20,000 docs: ai4bharat/sangraha :: published/hin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not stream from published/hin. Error: The directory at hf://datasets/ai4bharat/sangraha@8b813c3f62d37b2fa174d68c31e8b35ae2fe85e8/published/hin doesn't contain any data files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[stats:hin] docs=20,000 | mean=2211.0 | p50=1,549.5 | max=615,932\n",
            "📊 Plot saved to /content/drive/My Drive/LMA_SLM/reports/download_stats_hin.png\n",
            "✅ Wrote 20,000 records to /content/drive/My Drive/LMA_SLM/data/raw/hin.jsonl\n",
            "--------------------------------------------------\n",
            "--> [dl] Streaming first 20,000 docs: ai4bharat/sangraha :: verified/nep\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c018fd74f4f34460aad1a83e9b598e8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Reached streaming limit of 20000 for verified/nep.\n",
            "--> [dl] Streaming first 20,000 docs: ai4bharat/sangraha :: published/nep\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not stream from published/nep. Error: The directory at hf://datasets/ai4bharat/sangraha@8b813c3f62d37b2fa174d68c31e8b35ae2fe85e8/published/nep doesn't contain any data files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[stats:nep] docs=20,000 | mean=1936.2 | p50=1,223.5 | max=104,643\n",
            "📊 Plot saved to /content/drive/My Drive/LMA_SLM/reports/download_stats_nep.png\n",
            "✅ Wrote 20,000 records to /content/drive/My Drive/LMA_SLM/data/raw/nep.jsonl\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP: Install libraries and mount Google Drive\n",
        "# ==============================================================================\n",
        "print(\"--> Installing required libraries...\")\n",
        "!pip install -q datasets matplotlib\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import hashlib\n",
        "import statistics\n",
        "from typing import Iterable, Dict, List\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"--> Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CONFIGURATION: Replaces config.py and command-line args\n",
        "# ==============================================================================\n",
        "# Set the root path for your project inside Google Drive\n",
        "GDRIVE_PROJECT_PATH = \"/content/drive/My Drive/LMA_SLM\"\n",
        "\n",
        "class Config:\n",
        "    TEST_MODE = False\n",
        "    SAMPLE_DOCS_PER_LANG = 200\n",
        "    # Set the number of documents you want to sample per source.\n",
        "    # Streaming makes it easy to grab a small sample without downloading gigabytes.\n",
        "    per_lang_limit = 20000\n",
        "\n",
        "    RAW_DIR = os.path.join(GDRIVE_PROJECT_PATH, \"data\", \"raw\")\n",
        "    REPORTS_DIR = os.path.join(GDRIVE_PROJECT_PATH, \"reports\")\n",
        "    LANGS = [\"eng\", \"hin\", \"nep\"]\n",
        "    SANGRAHA_SOURCES = [\"verified\", \"published\"]\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. UTILITIES: Replaces utils/io_utils.py\n",
        "# ==============================================================================\n",
        "def ensure_dir(dir_path: str):\n",
        "    os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "def sha1(s: str) -> str:\n",
        "    return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def jsonl_writer(fpath: str, records: Iterable[Dict]):\n",
        "    count = 0\n",
        "    with open(fpath, \"w\", encoding=\"utf-8\") as f:\n",
        "        for record in records:\n",
        "            f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "            count += 1\n",
        "    print(f\"✅ Wrote {count:,} records to {fpath}\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. CORE LOGIC: CORRECTED to use streaming\n",
        "# ==============================================================================\n",
        "def stream_subset_lang(subset: str, lang: str, limit: int) -> Iterable[Dict]:\n",
        "    \"\"\"\n",
        "    Streams samples from the Sangraha dataset. This avoids downloading the\n",
        "    entire multi-gigabyte dataset to the Colab disk.\n",
        "    \"\"\"\n",
        "    data_dir = f\"{subset}/{lang}\"\n",
        "    limit_str = f\"first {limit:,}\" if limit else \"all\"\n",
        "    print(f\"--> [dl] Streaming {limit_str} docs: ai4bharat/sangraha :: {data_dir}\")\n",
        "\n",
        "    try:\n",
        "        # Use streaming=True to avoid massive downloads\n",
        "        ds = load_dataset(\"ai4bharat/sangraha\", data_dir=data_dir, streaming=True, split=\"train\")\n",
        "\n",
        "        n = 0\n",
        "        for ex in ds:\n",
        "            text = ex.get(\"text\", \"\")\n",
        "            if not text:\n",
        "                continue\n",
        "            doc_id = ex.get(\"doc_id\") or sha1(text)[:16]\n",
        "            yield {\"doc_id\": str(doc_id), \"subset\": subset, \"lang\": lang, \"text\": text}\n",
        "            n += 1\n",
        "            if limit and n >= limit:\n",
        "                print(f\"--> Reached streaming limit of {limit} for {data_dir}.\")\n",
        "                break\n",
        "    except Exception as e:\n",
        "        # This will catch errors like \"published/eng\" not existing and continue gracefully\n",
        "        print(f\"Could not stream from {data_dir}. Error: {e}\", file=sys.stderr)\n",
        "        return\n",
        "\n",
        "# ==============================================================================\n",
        "# 5. MAIN FUNCTION (UNCHANGED)\n",
        "# ==============================================================================\n",
        "def main():\n",
        "    args = {\n",
        "        \"out_dir\": cfg.RAW_DIR,\n",
        "        \"reports_dir\": cfg.REPORTS_DIR,\n",
        "        \"langs\": cfg.LANGS,\n",
        "        \"sources\": cfg.SANGRAHA_SOURCES,\n",
        "        \"per_lang_limit\": cfg.SAMPLE_DOCS_PER_LANG if cfg.TEST_MODE else cfg.per_lang_limit,\n",
        "    }\n",
        "\n",
        "    ensure_dir(args[\"out_dir\"])\n",
        "    ensure_dir(args[\"reports_dir\"])\n",
        "    print(f\"\\nOutput data will be saved to: {args['out_dir']}\")\n",
        "    print(f\"Reports will be saved to: {args['reports_dir']}\\n\")\n",
        "\n",
        "    for lang in args[\"langs\"]:\n",
        "        recs: List[Dict] = []\n",
        "        for subset in args[\"sources\"]:\n",
        "            recs.extend(list(stream_subset_lang(subset, lang, args[\"per_lang_limit\"])))\n",
        "\n",
        "        lengths = [len(r[\"text\"]) for r in recs]\n",
        "        if lengths:\n",
        "            print(f\"\\n[stats:{lang}] docs={len(recs):,} | mean={statistics.mean(lengths):.1f} | \"\n",
        "                  f\"p50={statistics.median(lengths):,} | max={max(lengths):,}\")\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.hist([min(l, 5000) for l in lengths], bins=50)\n",
        "            plt.title(f\"Document Length Distribution – {lang} ({len(recs):,} docs)\")\n",
        "            plt.xlabel(\"Character Count (capped at 5,000)\")\n",
        "            plt.ylabel(\"Number of Documents\")\n",
        "            out_png = os.path.join(args[\"reports_dir\"], f\"download_stats_{lang}.png\")\n",
        "            plt.savefig(out_png, dpi=120, bbox_inches=\"tight\")\n",
        "            plt.close()\n",
        "            print(f\"📊 Plot saved to {out_png}\")\n",
        "\n",
        "        out_path = os.path.join(args[\"out_dir\"], f\"{lang}.jsonl\")\n",
        "        jsonl_writer(out_path, recs)\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "# ==============================================================================\n",
        "# 6. RUN SCRIPT\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "goMbIExt7_uP",
        "outputId": "738a64c0-5fd5-457d-9580-5f8090f9efeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r '/content/LMA_dataset.zip' '/content/drive/MyDrive/LMA_SLM/data/raw'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_xUQZuFNWT_",
        "outputId": "84d509dd-8946-4f82-df46-614a1801cab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/drive/MyDrive/LMA_SLM/data/raw/ (stored 0%)\n",
            "  adding: content/drive/MyDrive/LMA_SLM/data/raw/eng.jsonl (deflated 61%)\n",
            "  adding: content/drive/MyDrive/LMA_SLM/data/raw/hin.jsonl (deflated 78%)\n",
            "  adding: content/drive/MyDrive/LMA_SLM/data/raw/nep.jsonl (deflated 79%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Run"
      ],
      "metadata": {
        "id": "dzUidi5joSnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP: Install libraries and mount Google Drive\n",
        "# ==============================================================================\n",
        "print(\"--> Installing required libraries...\")\n",
        "!pip install -q datasets matplotlib\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import hashlib\n",
        "import statistics\n",
        "from typing import Iterable, Dict, List\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"--> Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CONFIGURATION\n",
        "# ==============================================================================\n",
        "class Config:\n",
        "    \"\"\"Holds all the configuration for the data download process.\"\"\"\n",
        "    GDRIVE_PROJECT_PATH = \"/content/drive/My Drive/LMA_SLM\"\n",
        "    TEST_MODE = False\n",
        "\n",
        "    PER_LANG_LIMITS = {\n",
        "        \"eng\": 2250000,\n",
        "        \"hin\": 2050000,\n",
        "        \"nep\": 0,\n",
        "    }\n",
        "    SAMPLE_DOCS_PER_LANG = 1000\n",
        "    LANGS = [\"eng\", \"hin\", \"nep\"]\n",
        "    SANGRAHA_SOURCES = [\"verified\"]\n",
        "\n",
        "    @property\n",
        "    def RAW_DIR(self):\n",
        "        return os.path.join(self.GDRIVE_PROJECT_PATH, \"data\", \"raw\")\n",
        "\n",
        "    @property\n",
        "    def REPORTS_DIR(self):\n",
        "        return os.path.join(self.GDRIVE_PROJECT_PATH, \"reports\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. DATASET DOWNLOADER CLASS (ULTRA MEMORY-EFFICIENT)\n",
        "# ==============================================================================\n",
        "class DatasetDownloader:\n",
        "    \"\"\"\n",
        "    A class to handle streaming, processing, and saving the dataset.\n",
        "    This version is optimized for near-zero RAM growth by calculating stats iteratively.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: Config):\n",
        "        self.cfg = config\n",
        "        print(\"--> Initializing downloader...\")\n",
        "        self._setup_directories()\n",
        "\n",
        "    def _setup_directories(self):\n",
        "        \"\"\"Ensures all necessary output directories exist.\"\"\"\n",
        "        os.makedirs(self.cfg.RAW_DIR, exist_ok=True)\n",
        "        os.makedirs(self.cfg.REPORTS_DIR, exist_ok=True)\n",
        "        print(f\"Output data will be saved to: {self.cfg.RAW_DIR}\")\n",
        "        print(f\"Reports will be saved to: {self.cfg.REPORTS_DIR}\\n\")\n",
        "\n",
        "    def _stream_subset_lang(self, subset: str, lang: str, limit: int) -> Iterable[Dict]:\n",
        "        \"\"\"Generator that streams and yields processed records from the dataset.\"\"\"\n",
        "        data_dir = f\"{subset}/{lang}\"\n",
        "        try:\n",
        "            ds = load_dataset(\"ai4bharat/sangraha\", data_dir=data_dir, streaming=True, split=\"train\")\n",
        "            n = 0\n",
        "            for ex in ds:\n",
        "                text = ex.get(\"text\", \"\")\n",
        "                if not text: continue\n",
        "\n",
        "                doc_id = ex.get(\"doc_id\") or hashlib.sha1(text.encode(\"utf-8\")).hexdigest()[:16]\n",
        "                yield {\"doc_id\": str(doc_id), \"subset\": subset, \"lang\": lang, \"text\": text}\n",
        "\n",
        "                n += 1\n",
        "                if limit and n >= limit:\n",
        "                    print(f\"--> Reached streaming limit of {limit:,} for {data_dir}.\")\n",
        "                    break\n",
        "        except Exception as e:\n",
        "            print(f\"Could not stream from {data_dir}. Error: {e}\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "    def process_language(self, lang: str):\n",
        "        \"\"\"Processes a single language, streaming data to a file and calculating stats on the fly.\"\"\"\n",
        "        limit = self.cfg.SAMPLE_DOCS_PER_LANG if self.cfg.TEST_MODE else self.cfg.PER_LANG_LIMITS.get(lang, 0)\n",
        "        limit_str = f\"first {limit:,}\" if limit else \"all\"\n",
        "\n",
        "        print(f\"Processing language: '{lang}' (target: {limit_str} documents)\")\n",
        "\n",
        "        out_path = os.path.join(self.cfg.RAW_DIR, f\"{lang}.jsonl\")\n",
        "\n",
        "        # Iterative stats variables (low memory)\n",
        "        doc_count = 0\n",
        "        total_chars = 0\n",
        "        max_len = 0\n",
        "        min_len = float('inf')\n",
        "\n",
        "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for source in self.cfg.SANGRAHA_SOURCES:\n",
        "                print(f\"--> [dl] Starting stream from source: {source}/{lang}\")\n",
        "                for record in self._stream_subset_lang(source, lang, limit):\n",
        "                    f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "                    # Update stats iteratively\n",
        "                    length = len(record[\"text\"])\n",
        "                    doc_count += 1\n",
        "                    total_chars += length\n",
        "                    if length > max_len: max_len = length\n",
        "                    if length < min_len: min_len = length\n",
        "\n",
        "                    if limit and doc_count >= limit: break\n",
        "                if limit and doc_count >= limit: break\n",
        "\n",
        "        print(f\"✅ Wrote {doc_count:,} records to {out_path}\")\n",
        "\n",
        "        # Print the final, memory-safe statistics\n",
        "        if doc_count > 0:\n",
        "            mean_len = total_chars / doc_count\n",
        "            print(f\"\\n[stats:{lang}] docs={doc_count:,} | mean={mean_len:.1f} | min={min_len:,} | max={max_len:,}\")\n",
        "            # Note: Median and plotting are removed as they require storing all lengths in RAM.\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Runs the entire download and processing pipeline for all configured languages.\"\"\"\n",
        "        for lang in self.cfg.LANGS:\n",
        "            self.process_language(lang)\n",
        "        print(\"🎉 All languages processed successfully!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. RUN SCRIPT\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    config = Config()\n",
        "    downloader = DatasetDownloader(config)\n",
        "    downloader.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "3894b3bbe39e45a8a40ca38fc1fc7211",
            "44f3aef0aa71412e9bcae5bf97c0bdc1",
            "e396a1fd0dc84392b581ff55f7b753ef",
            "e848cb1a040f4ba290a16ff3e6b30c1b",
            "29d742b12a85410b87b09f0289c8b850",
            "e8e13502deb24af2a9a60c0ba47869d2",
            "fec0fbb2b0c649eb81505e481ed9e3a9",
            "f9f24abd870d4633b716af2a2acb9f13",
            "0ba2c6c1fa4244fbb3296b811bdc5e27",
            "25b5c37a2b7d430dabaaac4bc2bfe754",
            "39adae1c7e654c53a9d6ca722ce132e8",
            "e241844571854664b6a7cdd68004bd3a",
            "a2577ba01d314a88883e53108fe90378",
            "1e279e6abbd24a6d91b9a6e3451c1e77",
            "bc2c61f8ca044370b908f9c714ad2fa5",
            "c58612d3ee864fe9a44092cc01b0fb21",
            "d85755237d6244509a2bf6bbdfbc6604",
            "24e4f58f2afa48e7983ff9a9bc049ecc",
            "71ddb8cfa9ec41a1ac18044685a7edcf",
            "7b87215912034972b36f8dc50fe15d39",
            "1bbe9cb0eaab48b4acb2c4fc3f99621d",
            "dff5abf007104071bfc5db4d11acfdb9",
            "cd84386f85cc42e6b758c37bb77f4ece",
            "8729f623646046ea838dd855efc4e186",
            "97eae876a4304c5a98d38ee4c24eaaa7",
            "3cb14259464a47678bb161c7f09ee9f7",
            "ea57494af6a144a099aafcef8057cdb5",
            "ce1bdcf8264d407fbad092d91ce46ce4",
            "6a463d8fe7274183a5119166710db309",
            "efaaa106b98f421c82fb79f48882e7d7",
            "1961365df01546ba8557b39612a4e0b0",
            "44219b9f2c68494b9fbeba94b77a624c",
            "f382ec6e9aff42f2a633f346624c8c81"
          ]
        },
        "id": "dNdz9lshPOS5",
        "outputId": "fc77b57a-e8d4-423b-8384-1ab1d2735a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installing required libraries...\n",
            "--> Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "--> Initializing downloader...\n",
            "Output data will be saved to: /content/drive/My Drive/LMA_SLM/data/raw\n",
            "Reports will be saved to: /content/drive/My Drive/LMA_SLM/reports\n",
            "\n",
            "Processing language: 'eng' (target: first 2,250,000 documents)\n",
            "--> [dl] Starting stream from source: verified/eng\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/50 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3894b3bbe39e45a8a40ca38fc1fc7211"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote 2,250,000 records to /content/drive/My Drive/LMA_SLM/data/raw/eng.jsonl\n",
            "\n",
            "[stats:eng] docs=2,250,000 | mean=2684.3 | min=78 | max=1,017,515\n",
            "------------------------------------------------------------\n",
            "Processing language: 'hin' (target: first 2,050,000 documents)\n",
            "--> [dl] Starting stream from source: verified/hin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e241844571854664b6a7cdd68004bd3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote 2,050,000 records to /content/drive/My Drive/LMA_SLM/data/raw/hin.jsonl\n",
            "\n",
            "[stats:hin] docs=2,050,000 | mean=2198.3 | min=13 | max=1,053,637\n",
            "------------------------------------------------------------\n",
            "Processing language: 'nep' (target: all documents)\n",
            "--> [dl] Starting stream from source: verified/nep\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd84386f85cc42e6b758c37bb77f4ece"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP: Install libraries and mount Google Drive\n",
        "# ==============================================================================\n",
        "print(\"--> Installing required libraries...\")\n",
        "!pip install -q datasets matplotlib\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import hashlib\n",
        "import statistics\n",
        "from typing import Iterable, Dict, List\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(\"--> Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CONFIGURATION (MODIFIED FOR NEPALI ONLY)\n",
        "# ==============================================================================\n",
        "class Config:\n",
        "    \"\"\"Holds all the configuration for the data download process.\"\"\"\n",
        "    GDRIVE_PROJECT_PATH = \"/content/drive/My Drive/LMA_SLM\"\n",
        "    TEST_MODE = False\n",
        "\n",
        "    PER_LANG_LIMITS = {\n",
        "        \"nep\": 2100000, # Set a concrete high limit instead of 0\n",
        "    }\n",
        "    SAMPLE_DOCS_PER_LANG = 1000\n",
        "\n",
        "    # --- THIS IS THE KEY CHANGE ---\n",
        "    LANGS = [\"nep\"]\n",
        "\n",
        "    SANGRAHA_SOURCES = [\"verified\"]\n",
        "\n",
        "    @property\n",
        "    def RAW_DIR(self):\n",
        "        return os.path.join(self.GDRIVE_PROJECT_PATH, \"data\", \"raw\")\n",
        "\n",
        "    @property\n",
        "    def REPORTS_DIR(self):\n",
        "        return os.path.join(self.GDRIVE_PROJECT_PATH, \"reports\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 3. DATASET DOWNLOADER CLASS\n",
        "# ==============================================================================\n",
        "class DatasetDownloader:\n",
        "    \"\"\"\n",
        "    A class to handle streaming, processing, and saving the dataset.\n",
        "    This version is optimized for near-zero RAM growth and is resumable.\n",
        "    \"\"\"\n",
        "    def __init__(self, config: Config):\n",
        "        self.cfg = config\n",
        "        print(\"--> Initializing downloader...\")\n",
        "        self._setup_directories()\n",
        "\n",
        "    def _setup_directories(self):\n",
        "        \"\"\"Ensures all necessary output directories exist.\"\"\"\n",
        "        os.makedirs(self.cfg.RAW_DIR, exist_ok=True)\n",
        "        os.makedirs(self.cfg.REPORTS_DIR, exist_ok=True)\n",
        "        print(f\"Output data will be saved to: {self.cfg.RAW_DIR}\")\n",
        "        print(f\"Reports will be saved to: {self.cfg.REPORTS_DIR}\\n\")\n",
        "\n",
        "    def _stream_subset_lang(self, subset: str, lang: str, limit: int) -> Iterable[Dict]:\n",
        "        \"\"\"Generator that streams and yields processed records from the dataset.\"\"\"\n",
        "        data_dir = f\"{subset}/{lang}\"\n",
        "        try:\n",
        "            ds = load_dataset(\"ai4bharat/sangraha\", data_dir=data_dir, streaming=True, split=\"train\")\n",
        "            n = 0\n",
        "            for ex in ds:\n",
        "                text = ex.get(\"text\", \"\")\n",
        "                if not text: continue\n",
        "\n",
        "                doc_id = ex.get(\"doc_id\") or hashlib.sha1(text.encode(\"utf-8\")).hexdigest()[:16]\n",
        "                yield {\"doc_id\": str(doc_id), \"subset\": subset, \"lang\": lang, \"text\": text}\n",
        "\n",
        "                n += 1\n",
        "                if limit and n >= limit:\n",
        "                    print(f\"--> Reached streaming limit of {limit:,} for {data_dir}.\")\n",
        "                    break\n",
        "        except Exception as e:\n",
        "            print(f\"Could not stream from {data_dir}. Error: {e}\", file=sys.stderr)\n",
        "            return\n",
        "\n",
        "    def process_language(self, lang: str):\n",
        "        \"\"\"Processes a single language, streaming data to a file and calculating stats on the fly.\"\"\"\n",
        "        out_path = os.path.join(self.cfg.RAW_DIR, f\"{lang}.jsonl\")\n",
        "\n",
        "        # This check prevents accidental overwrites\n",
        "        if os.path.exists(out_path):\n",
        "            print(f\"✅ Output file already exists for '{lang}', skipping.\")\n",
        "            print(\"-\" * 60)\n",
        "            return\n",
        "\n",
        "        limit = self.cfg.SAMPLE_DOCS_PER_LANG if self.cfg.TEST_MODE else self.cfg.PER_LANG_LIMITS.get(lang, 0)\n",
        "        limit_str = f\"first {limit:,}\" if limit else \"all\"\n",
        "\n",
        "        print(f\"Processing language: '{lang}' (target: {limit_str} documents)\")\n",
        "\n",
        "        doc_count = 0\n",
        "        total_chars = 0\n",
        "        max_len = 0\n",
        "        min_len = float('inf')\n",
        "\n",
        "        with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
        "            for source in self.cfg.SANGRAHA_SOURCES:\n",
        "                print(f\"--> [dl] Starting stream from source: {source}/{lang}\")\n",
        "                for record in self._stream_subset_lang(source, lang, limit):\n",
        "                    f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "                    length = len(record[\"text\"])\n",
        "                    doc_count += 1\n",
        "                    total_chars += length\n",
        "                    if length > max_len: max_len = length\n",
        "                    if length < min_len: min_len = length\n",
        "\n",
        "                    if limit and doc_count >= limit: break\n",
        "                if limit and doc_count >= limit: break\n",
        "\n",
        "        print(f\"✅ Wrote {doc_count:,} records to {out_path}\")\n",
        "\n",
        "        if doc_count > 0:\n",
        "            mean_len = total_chars / doc_count\n",
        "            print(f\"\\n[stats:{lang}] docs={doc_count:,} | mean={mean_len:.1f} | min={min_len:,} | max={max_len:,}\")\n",
        "\n",
        "        print(\"-\" * 60)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"Runs the entire download and processing pipeline for all configured languages.\"\"\"\n",
        "        for lang in self.cfg.LANGS:\n",
        "            self.process_language(lang)\n",
        "        print(\"🎉 All languages processed successfully!\")\n",
        "\n",
        "# ==============================================================================\n",
        "# 4. RUN SCRIPT\n",
        "# ==============================================================================\n",
        "if __name__ == \"__main__\":\n",
        "    config = Config()\n",
        "    downloader = DatasetDownloader(config)\n",
        "    downloader.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338,
          "referenced_widgets": [
            "f521f378bab646b4a6147b708e0c7a75",
            "5ba7f3c4592f4302b3460395ded7df4a",
            "b79b19eb0de041cca9cc595f25161cb3",
            "0a9539844a864837bdbf2166246daf64",
            "84476289253e4205be60efe6d0f3c46e",
            "0fb03458453a404fa407e2be9f840471",
            "5d1a34ac1e53443f9eac07c0e6001d1c",
            "1d1808baea4848bfb91aa4a05d50c688",
            "7e1e0fe4a3614ff5901171e0da8d99ca",
            "7e4675ce886748e19fd2bb2a5aa81a9f",
            "0b2eb7a1b18d41bc8e0840bee457a549",
            "adc935d341ea421a9f380a60cb77639a",
            "0b5d203495a14ea6a6406d68a6568dad",
            "5c0ac1cd31bf4133a872942723d5ac00",
            "7427601ef0ee475d9afc752e9062cce9",
            "e36924d4a056481cb6280a9339407f71",
            "4b6f69b5576f456c82a556d92439211b",
            "0f19ecef46c04cefb93b85577dea418c",
            "105df3cf1ba84fc5972fa9bff47e3fb8",
            "297e6387fab3404d8e2be32b1bad1ef3",
            "47772694d8d945b5ad7c953cbeb72974",
            "2da011c8c2f44f209bf6af91cd37b181"
          ]
        },
        "id": "N0-tCLKUoOxn",
        "outputId": "03222790-4146-4474-ebdc-37d758fdf04b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installing required libraries...\n",
            "--> Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "--> Initializing downloader...\n",
            "Output data will be saved to: /content/drive/My Drive/LMA_SLM/data/raw\n",
            "Reports will be saved to: /content/drive/My Drive/LMA_SLM/reports\n",
            "\n",
            "Processing language: 'nep' (target: first 2,100,000 documents)\n",
            "--> [dl] Starting stream from source: verified/nep\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f521f378bab646b4a6147b708e0c7a75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Resolving data files:   0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "adc935d341ea421a9f380a60cb77639a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Wrote 2,100,000 records to /content/drive/My Drive/LMA_SLM/data/raw/nep.jsonl\n",
            "\n",
            "[stats:nep] docs=2,100,000 | mean=1933.7 | min=114 | max=224,324\n",
            "------------------------------------------------------------\n",
            "🎉 All languages processed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# 1. SETUP: Install libraries and mount Google Drive\n",
        "# ==============================================================================\n",
        "print(\"--> Installing required libraries...\")\n",
        "!pip install -q sentencepiece tokenizers matplotlib regex\n",
        "\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import hashlib\n",
        "import statistics\n",
        "import subprocess\n",
        "from pathlib import Path\n",
        "from typing import Iterable, Dict, List, Tuple\n",
        "\n",
        "from google.colab import drive\n",
        "import sentencepiece as spm\n",
        "import matplotlib.pyplot as plt\n",
        "from tokenizers import Tokenizer, normalizers, pre_tokenizers\n",
        "from tokenizers.models import Unigram\n",
        "\n",
        "print(\"--> Mounting Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# ==============================================================================\n",
        "# 2. CONFIGURATION: The single source of truth for the project\n",
        "# ==============================================================================\n",
        "class Config:\n",
        "    \"\"\"Holds all configuration for the project.\"\"\"\n",
        "    # --- Base Path (CHANGE THIS IF YOUR PROJECT IS IN A DIFFERENT FOLDER) ---\n",
        "    GDRIVE_PROJECT_PATH = \"/content/drive/My Drive/LMA_SLM\"\n",
        "\n",
        "    # --- Data Splitting Settings ---\n",
        "    LANGS = [\"eng\", \"hin\", \"nep\"]\n",
        "    TRAIN_RATIO = 0.98  # 98% of the data for training\n",
        "    VAL_RATIO = 0.01    # 1% for validation\n",
        "    # The rest (1%) will be used for testing\n",
        "    SEED = 42\n",
        "\n",
        "    # --- Tokenizer Training Settings ---\n",
        "    TOKENIZER_VOCABS = [48000, 64000] # Train models with these vocab sizes\n",
        "    TOKENIZER_TRAIN_DOCS_PER_LANG = 350_000 # Use 1M docs from each lang to train the tokenizer\n",
        "    TOKENIZER_ANALYZE_DOCS_PER_LANG = 20_000 # Use 20k docs to calculate metrics\n",
        "    TOKENIZER_CHAR_COVERAGE = 0.9995\n",
        "\n",
        "    # --- Automatically determined project directories ---\n",
        "    @property\n",
        "    def RAW_DIR(self): return Path(self.GDRIVE_PROJECT_PATH) / \"data\" / \"raw\"\n",
        "\n",
        "    @property\n",
        "    def SPLIT_DIR(self): return Path(self.GDRIVE_PROJECT_PATH) / \"data\" / \"splits\"\n",
        "\n",
        "    @property\n",
        "    def TOK_DIR(self): return Path(self.GDRIVE_PROJECT_PATH) / \"tokenizers\"\n",
        "\n",
        "    @property\n",
        "    def REPORTS_DIR(self): return Path(self.GDRIVE_PROJECT_PATH) / \"reports\"\n",
        "\n",
        "# Instantiate the config for the rest of the notebook\n",
        "cfg = Config()\n",
        "\n",
        "# --- Helper function to create directories ---\n",
        "def ensure_dir(p: Path):\n",
        "    p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"\\n✅ Configuration loaded. All paths point to your Google Drive.\")\n",
        "print(f\"   Raw Data Path: {cfg.RAW_DIR}\")\n",
        "print(f\"   Split Data Path: {cfg.SPLIT_DIR}\")\n",
        "print(f\"   Tokenizer Path: {cfg.TOK_DIR}\")"
      ],
      "metadata": {
        "id": "fpQuV7Pa-TUX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa7fa7f5-807a-4c4a-c2aa-fc9611a00cab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Installing required libraries...\n",
            "--> Mounting Google Drive...\n",
            "Mounted at /content/drive\n",
            "\n",
            "✅ Configuration loaded. All paths point to your Google Drive.\n",
            "   Raw Data Path: /content/drive/My Drive/LMA_SLM/data/raw\n",
            "   Split Data Path: /content/drive/My Drive/LMA_SLM/data/splits\n",
            "   Tokenizer Path: /content/drive/My Drive/LMA_SLM/tokenizers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# DATA HEALTH CHECK & REPAIR CELL\n",
        "# ==============================================================================\n",
        "# This script inspects each language's train.jsonl file for corruption\n",
        "# (missing newlines). It will only rewrite a file if it finds a problem.\n",
        "# ==============================================================================\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Make sure the Config class from the first cell is available ---\n",
        "# If running in a new session, you might need to re-run the first setup cell\n",
        "# or uncomment the minimal config below.\n",
        "# class Config:\n",
        "#     GDRIVE_PROJECT_PATH = \"/content/drive/My Drive/LMA_SLM\"\n",
        "#     LANGS = [\"eng\", \"hin\", \"nep\"]\n",
        "#     def SPLIT_DIR(self): return Path(self.GDRIVE_PROJECT_PATH) / \"data\" / \"splits\"\n",
        "# cfg = Config()\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def check_and_fix_jsonl(file_path: Path):\n",
        "    \"\"\"\n",
        "    Checks if a JSONL file is corrupted (missing newlines) and fixes it if needed,\n",
        "    providing verbose feedback throughout the process.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Checking file: {file_path.name} ---\")\n",
        "    if not file_path.exists():\n",
        "        print(f\"⚠️  File does not exist. Skipping.\")\n",
        "        return\n",
        "\n",
        "    # --- 1. Diagnosis Step ---\n",
        "    print(\"🔬 Performing health check...\")\n",
        "    is_corrupted = False\n",
        "    try:\n",
        "        with file_path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "            # Read a sample chunk to diagnose without using too much RAM\n",
        "            sample_chunk = f.read(2 * 1024 * 1024) # Read first 2MB\n",
        "            newline_count = sample_chunk.count('\\n')\n",
        "            json_boundary_count = sample_chunk.count('}{')\n",
        "\n",
        "            if newline_count <= 1 and json_boundary_count > 1:\n",
        "                is_corrupted = True\n",
        "                print(\"🚨 Diagnosis: File appears corrupted (single line with multiple JSON objects).\")\n",
        "            else:\n",
        "                print(\"✅ Diagnosis: File appears healthy with proper line breaks.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during the check: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 2. Fix Step (only if needed) ---\n",
        "    if not is_corrupted:\n",
        "        print(\"No fix needed.\")\n",
        "        return\n",
        "\n",
        "    print(\"\\n🔧 Starting repair process...\")\n",
        "    corrected_path = file_path.with_name(f\"{file_path.stem}.reformatted.jsonl\")\n",
        "    print(f\"   - Source:      {file_path.name}\")\n",
        "    print(f\"   - Destination: {corrected_path.name}\")\n",
        "\n",
        "    buffer_size_mb = 10\n",
        "    buffer_size = buffer_size_mb * 1024 * 1024\n",
        "    chunks_processed = 0\n",
        "\n",
        "    try:\n",
        "        with file_path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f_in, \\\n",
        "             corrected_path.open(\"w\", encoding=\"utf-8\") as f_out:\n",
        "\n",
        "            while True:\n",
        "                chunk = f_in.read(buffer_size)\n",
        "                if not chunk:\n",
        "                    break\n",
        "\n",
        "                reformatted_chunk = chunk.replace('}{', '}\\n{')\n",
        "                f_out.write(reformatted_chunk)\n",
        "                chunks_processed += 1\n",
        "                print(f\"   ...processed {chunks_processed * buffer_size_mb} MB...\")\n",
        "\n",
        "        print(f\"\\n✅ Repair complete. New file saved.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during file repair: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 3. Verification Step ---\n",
        "    print(\"\\n🔍 Verifying the new file...\")\n",
        "    try:\n",
        "        with corrected_path.open(\"r\", encoding=\"utf-8\") as f:\n",
        "            print(\"First 3 records from the new file:\")\n",
        "            for i, line in enumerate(f):\n",
        "                if i >= 3:\n",
        "                    break\n",
        "                try:\n",
        "                    # Try parsing to confirm it's valid JSON\n",
        "                    record = json.loads(line)\n",
        "                    # Print a snippet of the text\n",
        "                    text_snippet = record.get(\"text\", \"N/A\")[:100] + \"...\"\n",
        "                    print(f\"  Record {i+1}: {text_snippet}\")\n",
        "                except json.JSONDecodeError:\n",
        "                    print(f\"  Record {i+1}: FAILED to parse as JSON. The fix may not have worked correctly.\")\n",
        "        print(\"✅ Verification successful. The new file is correctly formatted.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during verification: {e}\")\n",
        "\n",
        "\n",
        "# --- Run the health check for all languages ---\n",
        "for lang in cfg.LANGS:\n",
        "    file_to_check = cfg.SPLIT_DIR / lang / \"train.jsonl\"\n",
        "    check_and_fix_jsonl(file_to_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tt7jsxyCxYsu",
        "outputId": "6f9ebd09-977c-401e-bbd4-df0ee64b9553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Checking file: train.jsonl ---\n",
            "🔬 Performing health check...\n",
            "✅ Diagnosis: File appears healthy with proper line breaks.\n",
            "No fix needed.\n",
            "\n",
            "--- Checking file: train.jsonl ---\n",
            "🔬 Performing health check...\n",
            "✅ Diagnosis: File appears healthy with proper line breaks.\n",
            "No fix needed.\n",
            "\n",
            "--- Checking file: train.jsonl ---\n",
            "🔬 Performing health check...\n",
            "✅ Diagnosis: File appears healthy with proper line breaks.\n",
            "No fix needed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# ADVANCED FILE DIAGNOSTICS\n",
        "# ==============================================================================\n",
        "# This script will scan a file line-by-line to find the length of the\n",
        "# longest line, without loading the whole file into memory.\n",
        "# ==============================================================================\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Make sure the Config class from the first cell is available ---\n",
        "cfg = Config()\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def find_longest_line(file_path: Path):\n",
        "    print(f\"--- Analyzing line lengths in: {file_path.name} ---\")\n",
        "    if not file_path.exists():\n",
        "        print(f\"⚠️  File does not exist. Skipping.\")\n",
        "        return\n",
        "\n",
        "    max_len = 0\n",
        "    max_line_num = -1\n",
        "\n",
        "    with file_path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        for i, line in enumerate(f):\n",
        "            # Check length of the current line\n",
        "            current_len = len(line)\n",
        "            if current_len > max_len:\n",
        "                max_len = current_len\n",
        "                max_line_num = i + 1\n",
        "\n",
        "            # Print progress update\n",
        "            if (i + 1) % 200000 == 0:\n",
        "                print(f\"  ...scanned {i+1:,} lines...\")\n",
        "\n",
        "    print(\"\\n--- Analysis Complete ---\")\n",
        "    print(f\"Total lines scanned: {i+1:,}\")\n",
        "    print(f\"Longest line found at line number: {max_line_num:,}\")\n",
        "    print(f\"Length of longest line: {max_len:,} characters\")\n",
        "\n",
        "    if max_len > 10_000_000: # 10 million characters\n",
        "        print(\"\\n🚨 Verdict: Found an extremely large line, which is the likely cause of the RAM crash.\")\n",
        "    elif max_len > 1_000_000: # 1 million characters\n",
        "        print(\"\\n⚠️ Verdict: Found a very long line. This could be problematic and might be the cause.\")\n",
        "    else:\n",
        "        print(\"\\n✅ Verdict: No abnormally large lines found. The issue may lie elsewhere.\")\n",
        "\n",
        "\n",
        "# --- Run the analysis on the Nepali training data ---\n",
        "nepali_file_to_check = cfg.SPLIT_DIR / \"nep\" / \"train.jsonl\"\n",
        "find_longest_line(nepali_file_to_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iH6BRKDL2atL",
        "outputId": "8e354ee1-7ab8-4ede-ec5f-2b4da8f67796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Analyzing line lengths in: train.jsonl ---\n",
            "  ...scanned 200,000 lines...\n",
            "  ...scanned 400,000 lines...\n",
            "  ...scanned 600,000 lines...\n",
            "  ...scanned 800,000 lines...\n",
            "  ...scanned 1,000,000 lines...\n",
            "  ...scanned 1,200,000 lines...\n",
            "  ...scanned 1,400,000 lines...\n",
            "  ...scanned 1,600,000 lines...\n",
            "  ...scanned 1,800,000 lines...\n",
            "  ...scanned 2,000,000 lines...\n",
            "\n",
            "--- Analysis Complete ---\n",
            "Total lines scanned: 2,058,000\n",
            "Longest line found at line number: 1,314,539\n",
            "Length of longest line: 225,245 characters\n",
            "\n",
            "✅ Verdict: No abnormally large lines found. The issue may lie elsewhere.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================================\n",
        "# FINAL DIAGNOSTICS: Deep Scan for the Problematic Record\n",
        "# ==============================================================================\n",
        "# This script performs a low-level, memory-safe scan of a JSONL file to\n",
        "# identify the exact line and error type causing system crashes.\n",
        "# ==============================================================================\n",
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# --- Make sure the Config class from the first cell is available ---\n",
        "# If running in a new session, re-run the first setup cell.\n",
        "# cfg = Config()\n",
        "# --------------------------------------------------------------------------\n",
        "\n",
        "def deep_scan_jsonl_file(file_path: Path):\n",
        "    \"\"\"\n",
        "    Scans a JSONL file record by record to find specific data errors.\n",
        "\n",
        "    Checks for:\n",
        "    1. JSON Formatting Errors (Is the line valid JSON?)\n",
        "    2. Schema Errors (Does the record have a 'text' field that is a string?)\n",
        "    3. Encoding Errors (Does the text contain malformed Unicode characters?)\n",
        "    \"\"\"\n",
        "    print(f\"--- Starting deep forensic scan of: {file_path.name} ---\")\n",
        "    if not file_path.exists():\n",
        "        print(f\"❌ ERROR: File not found at {file_path}. Cannot proceed.\")\n",
        "        return\n",
        "\n",
        "    found_errors = 0\n",
        "    max_errors_to_report = 10 # Stop after finding a few errors\n",
        "\n",
        "    with file_path.open(\"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
        "        for line_num, line in enumerate(f, 1):\n",
        "\n",
        "            if found_errors >= max_errors_to_report:\n",
        "                print(f\"\\nStopping scan after finding {max_errors_to_report} errors.\")\n",
        "                break\n",
        "\n",
        "            # --- Check 1: Is the line valid JSON? ---\n",
        "            try:\n",
        "                record = json.loads(line)\n",
        "            except json.JSONDecodeError:\n",
        "                found_errors += 1\n",
        "                print(\"\\n\" + \"=\"*80)\n",
        "                print(f\"🚨 CRITICAL ERROR FOUND at Line: {line_num:,}\")\n",
        "                print(f\"   - Problem: Invalid JSON format. The line could not be parsed.\")\n",
        "                print(f\"   - Snippet: {line[:200]}...\")\n",
        "                print(\"=\"*80)\n",
        "                continue # Move to the next line\n",
        "\n",
        "            # --- Check 2: Does it have a valid 'text' field? ---\n",
        "            text = record.get(\"text\")\n",
        "            if text is None:\n",
        "                found_errors += 1\n",
        "                print(\"\\n\" + \"=\"*80)\n",
        "                print(f\"🚨 CRITICAL ERROR FOUND at Line: {line_num:,}\")\n",
        "                print(f\"   - Problem: Schema error. Record is missing the 'text' field.\")\n",
        "                print(f\"   - Snippet: {str(record)[:200]}...\")\n",
        "                print(\"=\"*80)\n",
        "                continue\n",
        "\n",
        "            if not isinstance(text, str):\n",
        "                found_errors += 1\n",
        "                print(\"\\n\" + \"=\"*80)\n",
        "                print(f\"🚨 CRITICAL ERROR FOUND at Line: {line_num:,}\")\n",
        "                print(f\"   - Problem: Schema error. The 'text' field is not a string (it's a {type(text)}).\")\n",
        "                print(f\"   - Snippet: {str(record)[:200]}...\")\n",
        "                print(\"=\"*80)\n",
        "                continue\n",
        "\n",
        "            # --- Check 3: Does the text contain malformed characters? ---\n",
        "            try:\n",
        "                # This is a strict test. If it fails, there's a deep encoding issue.\n",
        "                text.encode('utf-8', 'strict')\n",
        "            except UnicodeEncodeError as e:\n",
        "                found_errors += 1\n",
        "                print(\"\\n\" + \"=\"*80)\n",
        "                print(f\"🚨 CRITICAL ERROR FOUND at Line: {line_num:,}\")\n",
        "                print(f\"   - Problem: Corrupted Unicode. The text contains a malformed character sequence.\")\n",
        "                print(f\"   - Details: {e}\")\n",
        "                # Try to find the problematic character position\n",
        "                bad_char_pos = e.start\n",
        "                context_snippet = text[max(0, bad_char_pos-50):min(len(text), bad_char_pos+50)]\n",
        "                print(f\"   - Context: ...{context_snippet}...\")\n",
        "                print(\"=\"*80)\n",
        "                continue\n",
        "\n",
        "            # --- Progress Update ---\n",
        "            if line_num % 250000 == 0:\n",
        "                print(f\"   ...scanned {line_num:,} lines. No critical errors found so far.\")\n",
        "\n",
        "    print(\"\\n--- Scan Complete ---\")\n",
        "    if found_errors == 0:\n",
        "        print(\"✅ No critical errors were found in the file. The issue is likely environmental.\")\n",
        "    else:\n",
        "        print(f\"Found a total of {found_errors} critical error(s).\")\n",
        "\n",
        "# --- Run the deep scan on the Nepali training data ---\n",
        "nepali_file_to_check = cfg.SPLIT_DIR / \"nep\" / \"train.jsonl\"\n",
        "deep_scan_jsonl_file(nepali_file_to_check)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ivczz_1EWqrv",
        "outputId": "4976f783-242d-4714-f226-99b9ac316b0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting deep forensic scan of: train.jsonl ---\n",
            "   ...scanned 250,000 lines. No critical errors found so far.\n",
            "   ...scanned 500,000 lines. No critical errors found so far.\n",
            "   ...scanned 750,000 lines. No critical errors found so far.\n",
            "   ...scanned 1,000,000 lines. No critical errors found so far.\n",
            "   ...scanned 1,250,000 lines. No critical errors found so far.\n",
            "   ...scanned 1,500,000 lines. No critical errors found so far.\n",
            "   ...scanned 1,750,000 lines. No critical errors found so far.\n",
            "   ...scanned 2,000,000 lines. No critical errors found so far.\n",
            "\n",
            "--- Scan Complete ---\n",
            "✅ No critical errors were found in the file. The issue is likely environmental.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- installs -----------------------------------------------------------------------------\n",
        "!pip -q install sentencepiece tokenizers zstandard psutil >/dev/null\n",
        "\n",
        "import os, sys, io, re, json, shutil, subprocess, math, gzip, lzma, random\n",
        "from typing import Dict, List, Tuple, Optional\n",
        "\n",
        "# Reduce thread fan-out on shared VMs\n",
        "os.environ.setdefault(\"OMP_NUM_THREADS\", \"4\")\n",
        "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
        "os.environ.setdefault(\"VECLIB_MAXIMUM_THREADS\", \"1\")\n",
        "os.environ.setdefault(\"NUMEXPR_NUM_THREADS\", \"1\")\n",
        "\n",
        "# --- libs ---------------------------------------------------------------------------------\n",
        "import sentencepiece as spm\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import Unigram as HFUnigram\n",
        "from tokenizers import normalizers, pre_tokenizers\n",
        "from tokenizers.normalizers import NFKC\n",
        "from tokenizers.pre_tokenizers import Whitespace, Sequence\n",
        "from tokenizers import AddedToken\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "\n",
        "# ==== CONFIG ==============================================================================\n",
        "# Drive paths\n",
        "DRIVE_SPLITS_DIR = \"/content/drive/MyDrive/LMA_SLM/data/splits\"\n",
        "DRIVE_RAW_DIR    = \"/content/drive/MyDrive/LMA_SLM/data/raw\"   # optional fallback\n",
        "\n",
        "# Output roots (persist on Drive)\n",
        "OUT_DIR_DRIVE     = \"/content/drive/MyDrive/LMA_SLM/tokenizers\"\n",
        "REPORTS_DIR_DRIVE = \"/content/drive/MyDrive/LMA_SLM/tokenizer_reports\"\n",
        "\n",
        "# Tokenizer languages\n",
        "LANGS = [\"eng\", \"hin\", \"nep\"]\n",
        "\n",
        "# ---- Core RAM fix: train on a byte-budgeted subset ---------------------------------------\n",
        "TRAIN_BYTE_BUDGET_TOTAL = 120_000_000      # ~120MB UTF-8 text total (tune 80–150MB)\n",
        "MAX_CHARS_PER_LINE      = 2000             # trim ultra-long lines before counting bytes\n",
        "ROUND_ROBIN_CHUNK       = 200_000          # read this many lines per language per pass\n",
        "SHUFFLE_WITHIN_PASS     = False            # set True to shuffle buffers per pass\n",
        "\n",
        "# Pretok & placeholders\n",
        "USE_INDIC_PRETOK = True\n",
        "USE_PLACEHOLDERS = True\n",
        "ADD_LANG_TAGS    = True\n",
        "\n",
        "# SPM training params (safe for Colab):\n",
        "VOCAB_SIZES = [48000, 64000]\n",
        "CHAR_COVERAGE = 0.9999\n",
        "NUM_THREADS = 4\n",
        "\n",
        "# IMPORTANT: Because we pre-sample by bytes, keep this 0 so SPM won't reload more data.\n",
        "INPUT_SENTENCE_SIZE = 0\n",
        "\n",
        "# Lighter EM\n",
        "SEED_SENTENCEPIECE_SIZE = 200_000\n",
        "NUM_SUB_ITERATIONS      = 1\n",
        "\n",
        "# Analysis sample per language for metrics\n",
        "ANALYZE_DOCS_PER_LANG = 8000\n",
        "\n",
        "# Locked tokens file (optional; one token per line)\n",
        "LOCK_TOKENS_FILE = \"\"\n",
        "\n",
        "# ==========================================================================================\n",
        "\n",
        "try:\n",
        "    import zstandard as zstd\n",
        "except Exception:\n",
        "    zstd = None\n",
        "\n",
        "def ensure_dir(p: str):\n",
        "    os.makedirs(p, exist_ok=True)\n",
        "\n",
        "def mem_mb():\n",
        "    try:\n",
        "        import psutil\n",
        "        vm = psutil.virtual_memory()\n",
        "        return f\"{(vm.total - vm.available)/ (1024*1024):.1f} MB\"\n",
        "    except Exception:\n",
        "        return \"n/a\"\n",
        "\n",
        "def _open_smart(path: str):\n",
        "    lower = path.lower()\n",
        "    if lower.endswith(\".gz\"):\n",
        "        return gzip.open(path, \"rb\")\n",
        "    if lower.endswith(\".xz\"):\n",
        "        return lzma.open(path, \"rb\")\n",
        "    if lower.endswith(\".zst\"):\n",
        "        if zstd is None:\n",
        "            raise RuntimeError(f\"zstandard not installed but needed: {path}\")\n",
        "        dctx = zstd.ZstdDecompressor()\n",
        "        return dctx.stream_reader(open(path, \"rb\"))\n",
        "    return open(path, \"rb\")\n",
        "\n",
        "def jsonl_iter_texts(path: str, limit: Optional[int] = None,\n",
        "                     encoding: str = \"utf-8\", errors: str = \"replace\"):\n",
        "    bad = 0; n = 0\n",
        "    with _open_smart(path) as fb:\n",
        "        with io.TextIOWrapper(fb, encoding=encoding, errors=errors, newline=\"\") as f:\n",
        "            for raw in f:\n",
        "                s = raw.strip()\n",
        "                if not s: continue\n",
        "                try:\n",
        "                    rec = json.loads(s)\n",
        "                except Exception:\n",
        "                    bad += 1\n",
        "                    if bad <= 3:\n",
        "                        print(f\"[warn] bad JSON in {os.path.basename(path)} (#{bad})\")\n",
        "                    continue\n",
        "                t = rec.get(\"text\",\"\")\n",
        "                if t:\n",
        "                    yield t\n",
        "                    n += 1\n",
        "                    if limit and n >= limit:\n",
        "                        break\n",
        "\n",
        "# --- light pretok / placeholders -----------------------------------------------------------\n",
        "def indic_pretokenize(text: str) -> str:\n",
        "    try:\n",
        "        import regex as re2\n",
        "        pieces = re2.split(r\"(\\p{Z}|\\p{P}|\\p{S})+\", text)\n",
        "        toks = [p for p in pieces if p and not p.isspace()]\n",
        "        return \" \".join(toks)\n",
        "    except Exception:\n",
        "        parts = re.split(r\"([,.:;!?\\\"'()\\[\\]{}\\-–—_/\\\\]|[\\s]+)\", text)\n",
        "        toks = [p for p in parts if p and not p.isspace()]\n",
        "        return \" \".join(toks)\n",
        "\n",
        "_URL_RE   = re.compile(r'https?://\\S+')\n",
        "_EMAIL_RE = re.compile(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b')\n",
        "_DATE_RE  = re.compile(r'\\b\\d{1,4}([./-]\\d{1,2}){1,2}\\b')\n",
        "_NUM_RE   = re.compile(r'\\b\\d+\\b')\n",
        "\n",
        "def apply_placeholders(text: str) -> str:\n",
        "    t = _URL_RE.sub(\"<URL>\", text)\n",
        "    t = _EMAIL_RE.sub(\"<EMAIL>\", t)\n",
        "    t = _DATE_RE.sub(\"<DATE>\", t)\n",
        "    t = _NUM_RE.sub(\"<NUM>\", t)\n",
        "    return t\n",
        "\n",
        "LANG_TAGS = {\"eng\": \"<eng>\", \"hin\": \"<hin>\", \"nep\": \"<nep>\"}\n",
        "\n",
        "def pick_train_file(lang: str, splits_dir: str, raw_dir: str) -> str:\n",
        "    p1 = os.path.join(splits_dir, lang, \"train.jsonl\")\n",
        "    p2 = os.path.join(raw_dir, f\"{lang}.jsonl\")\n",
        "    if os.path.exists(p1):\n",
        "        print(f\"[src:{lang}] {p1}\")\n",
        "        return p1\n",
        "    print(f\"[src:{lang}] (fallback) {p2}\")\n",
        "    return p2\n",
        "\n",
        "def pick_eval_files(lang: str, splits_dir: str, raw_dir: str) -> List[str]:\n",
        "    cand = [\n",
        "        os.path.join(splits_dir, lang, \"val.jsonl\"),\n",
        "        os.path.join(splits_dir, lang, \"train.jsonl\"),\n",
        "        os.path.join(raw_dir, f\"{lang}.jsonl\"),\n",
        "    ]\n",
        "    seen, out = set(), []\n",
        "    for p in cand:\n",
        "        if os.path.exists(p) and p not in seen:\n",
        "            seen.add(p); out.append(p)\n",
        "    return out\n",
        "\n",
        "def format_num(n: float) -> str:\n",
        "    for unit, div in ((\"T\",1e12),(\"B\",1e9),(\"M\",1e6),(\"K\",1e3)):\n",
        "        if n >= div: return f\"{n/div:.2f}{unit}\"\n",
        "    return f\"{n:.0f}\"\n",
        "\n",
        "def load_lock_tokens(path: Optional[str]) -> List[str]:\n",
        "    if not path: return []\n",
        "    if not os.path.exists(path):\n",
        "        print(f\"[lock] not found: {path}\"); return []\n",
        "    toks=[]\n",
        "    with open(path,\"r\",encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            s=line.strip()\n",
        "            if s and not s.startswith(\"#\"):\n",
        "                toks.append(s)\n",
        "    print(f\"[lock] loaded {len(toks)} tokens\")\n",
        "    return toks\n",
        "\n",
        "# --- NEW: build byte-budgeted subset (per language quota) --------------------------------\n",
        "def build_byte_budget_subset(splits_dir: str, raw_dir: str, langs: List[str],\n",
        "                             byte_budget_total: int, max_chars_per_line: int,\n",
        "                             use_indic_pretok: bool, use_placeholders: bool,\n",
        "                             add_lang_tags: bool, out_file: str):\n",
        "    ensure_dir(os.path.dirname(out_file))\n",
        "    per_lang_quota = byte_budget_total // max(1,len(langs))\n",
        "    totals: Dict[str,int] = {l:0 for l in langs}\n",
        "    written: Dict[str,int] = {l:0 for l in langs}\n",
        "    with open(out_file, \"w\", encoding=\"utf-8\") as out:\n",
        "        print(f\"[subset] byte budget total={format_num(byte_budget_total)} (~UTF-8), per-lang≈{format_num(per_lang_quota)}\")\n",
        "        # Round-robin over languages with bounded passes to avoid scanning entire corpora\n",
        "        active = True\n",
        "        passes = 0\n",
        "        while active:\n",
        "            active = False\n",
        "            passes += 1\n",
        "            for lang in langs:\n",
        "                if totals[lang] >= per_lang_quota:\n",
        "                    continue\n",
        "                src = pick_train_file(lang, splits_dir, raw_dir)\n",
        "                # read a chunk of lines for this pass\n",
        "                took = 0\n",
        "                lines = []\n",
        "                for t in jsonl_iter_texts(src, limit=ROUND_ROBIN_CHUNK):\n",
        "                    if use_placeholders:\n",
        "                        t = apply_placeholders(t)\n",
        "                    if use_indic_pretok:\n",
        "                        t = indic_pretokenize(t)\n",
        "                    if add_lang_tags:\n",
        "                        t = f\"{LANG_TAGS.get(lang, f'<{lang}>')} {t}\"\n",
        "                    if max_chars_per_line and len(t) > max_chars_per_line:\n",
        "                        t = t[:max_chars_per_line]\n",
        "                    lines.append(t)\n",
        "                if not lines:\n",
        "                    continue\n",
        "                if SHUFFLE_WITHIN_PASS:\n",
        "                    random.shuffle(lines)\n",
        "                for t in lines:\n",
        "                    b = len(t.encode(\"utf-8\")) + 1  # +1 for newline\n",
        "                    if totals[lang] + b > per_lang_quota:\n",
        "                        break\n",
        "                    out.write(t.replace(\"\\n\",\" \") + \"\\n\")\n",
        "                    totals[lang] += b\n",
        "                    written[lang] += 1\n",
        "                    took += 1\n",
        "                if took:\n",
        "                    active = True\n",
        "                    print(f\"[subset:{lang}] +{took} lines (pass {passes}) bytes={format_num(totals[lang])} mem={mem_mb()}\")\n",
        "            # stop if no language could add more\n",
        "        print(\"[subset] DONE per-lang bytes:\", {k: format_num(v) for k,v in totals.items()})\n",
        "        print(\"[subset] lines written:\", {k: written[k] for k in langs})\n",
        "    return written, totals\n",
        "\n",
        "# --- SPM train -------------------------------------------------------------------------------\n",
        "def train_sp_unigram(corpus_path: str, model_prefix: str, vocab_size: int):\n",
        "    print(f\"[spm] train | vocab={vocab_size} char_cov={CHAR_COVERAGE} threads={NUM_THREADS} iss={INPUT_SENTENCE_SIZE}\")\n",
        "    # prepare symbols\n",
        "    lang_syms = list(LANG_TAGS.values()) if ADD_LANG_TAGS else []\n",
        "    placeholders = [\"<URL>\",\"<EMAIL>\",\"<NUM>\",\"<DATE>\"] if USE_PLACEHOLDERS else []\n",
        "    locked = load_lock_tokens(LOCK_TOKENS_FILE)\n",
        "    user_defined = lang_syms + placeholders + locked\n",
        "\n",
        "    spm.SentencePieceTrainer.Train(\n",
        "        input=corpus_path,\n",
        "        model_prefix=model_prefix,\n",
        "        model_type=\"unigram\",\n",
        "        vocab_size=vocab_size,\n",
        "        character_coverage=CHAR_COVERAGE,\n",
        "        num_threads=max(1, NUM_THREADS),\n",
        "\n",
        "        # CRUCIAL: we already pre-sampled by bytes; don't let SPM re-sample.\n",
        "        input_sentence_size=max(0, INPUT_SENTENCE_SIZE),\n",
        "\n",
        "        # Lighter EM to keep memory in check\n",
        "        seed_sentencepiece_size=max(100000, SEED_SENTENCEPIECE_SIZE),\n",
        "        num_sub_iterations=max(1, NUM_SUB_ITERATIONS),\n",
        "\n",
        "        # Robustness/settings\n",
        "        byte_fallback=True,\n",
        "        treat_whitespace_as_suffix=True,\n",
        "        remove_extra_whitespaces=True,\n",
        "        max_sentence_length=4096,   # keep long lines bounded further\n",
        "\n",
        "        user_defined_symbols=\",\".join(user_defined) if user_defined else \"\",\n",
        "        hard_vocab_limit=False,\n",
        "        train_extremely_large_corpus=True,  # harmless when data is small\n",
        "        self_test_sample_size=0\n",
        "    )\n",
        "    print(f\"[spm] wrote {model_prefix}.model / .vocab | mem={mem_mb()}\")\n",
        "\n",
        "# --- HF export -----------------------------------------------------------------------------\n",
        "def load_sp_vocab(vocab_path: str) -> Tuple[List[Tuple[str, float]], int]:\n",
        "    vocab=[]; unk_id=0\n",
        "    with open(vocab_path,\"r\",encoding=\"utf-8\") as f:\n",
        "        for idx, line in enumerate(f):\n",
        "            s=line.rstrip(\"\\n\")\n",
        "            if not s: continue\n",
        "            piece, score = s.split(\"\\t\")\n",
        "            vocab.append((piece, float(score)))\n",
        "            if piece == \"<unk>\":\n",
        "                unk_id = idx\n",
        "    return vocab, unk_id\n",
        "\n",
        "def export_hf(sp_vocab: str, sp_model: str, out_dir: str):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    vocab, unk_id = load_sp_vocab(sp_vocab)\n",
        "    tok = Tokenizer(HFUnigram(vocab=vocab, unk_id=unk_id))\n",
        "    tok.normalizer = normalizers.Sequence([NFKC()])\n",
        "    tok.pre_tokenizer = Sequence([Whitespace()])\n",
        "\n",
        "    sentinels=[]  # set if you want <extra_id_*>\n",
        "    lang_syms = list(LANG_TAGS.values()) if ADD_LANG_TAGS else []\n",
        "    placeholders = [\"<URL>\",\"<EMAIL>\",\"<NUM>\",\"<DATE>\"] if USE_PLACEHOLDERS else []\n",
        "    locked = load_lock_tokens(LOCK_TOKENS_FILE)\n",
        "\n",
        "    specials = [\"<unk>\",\"<s>\",\"</s>\"] + sentinels\n",
        "    tok.add_special_tokens([AddedToken(s, single_word=False, normalized=False) for s in specials])\n",
        "    tok.add_tokens([AddedToken(s, single_word=False, normalized=False) for s in (lang_syms + placeholders + locked)])\n",
        "\n",
        "    tok.post_processor = TemplateProcessing(\n",
        "        single=\"<s> $A </s>\", pair=\"<s> $A </s> </s> $B </s>\",\n",
        "        special_tokens=[(\"<s>\", 0), (\"</s>\", 0)]\n",
        "    )\n",
        "\n",
        "    out_json = os.path.join(out_dir, \"tokenizer.json\")\n",
        "    tok.save(out_json)\n",
        "    with open(os.path.join(out_dir, \"special_tokens_map.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"unk_token\":\"<unk>\",\"bos_token\":\"<s>\",\"eos_token\":\"</s>\",\n",
        "                   \"additional_special_tokens\": sentinels + lang_syms + placeholders + locked}, f, indent=2)\n",
        "    with open(os.path.join(out_dir, \"tokenizer_config.json\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"model_max_length\":2048,\"unk_token\":\"<unk>\",\"bos_token\":\"<s>\",\"eos_token\":\"</s>\",\n",
        "                   \"special_tokens_map_file\":\"special_tokens_map.json\"}, f, indent=2)\n",
        "    print(f\"[hf] wrote {out_json} (+sidecars)\")\n",
        "\n",
        "# --- Metrics (streaming) -------------------------------------------------------------------\n",
        "def _is_byte_piece(sp: spm.SentencePieceProcessor, tid: int) -> bool:\n",
        "    p = sp.IdToPiece(tid)\n",
        "    return p.startswith(\"<0x\") and p.endswith(\">\")\n",
        "\n",
        "def compute_metrics(sp_model_path: str, files_per_lang: Dict[str, List[str]], max_docs_per_lang: int):\n",
        "    sp = spm.SentencePieceProcessor(); sp.Load(sp_model_path)\n",
        "    import math\n",
        "    bins = [0,8,16,32,64,128,256,512,1024,2048,4096,8192,16384]\n",
        "    def bini(x):\n",
        "        for i, b in enumerate(bins):\n",
        "            if x <= b: return i\n",
        "        return len(bins)-1\n",
        "\n",
        "    results={}\n",
        "    for lang, files in files_per_lang.items():\n",
        "        total_bytes = total_tokens = docs_seen = 0\n",
        "        mean = 0.0; m2 = 0.0; min_len = 10**9; max_len = 0\n",
        "        hist = [0]*len(bins); byte_tok = 0\n",
        "        for p in files:\n",
        "            if not os.path.exists(p): continue\n",
        "            for t in jsonl_iter_texts(p, limit=None):\n",
        "                b = len(t.encode(\"utf-8\"))\n",
        "                ids = sp.EncodeAsIds(t)\n",
        "                L = len(ids)\n",
        "                total_bytes += b; total_tokens += L\n",
        "                byte_tok += sum(1 for tid in ids if _is_byte_piece(sp, tid))\n",
        "                docs_seen += 1\n",
        "                d = L - mean; mean += d / docs_seen; m2 += d * (L - mean)\n",
        "                min_len = min(min_len, L); max_len = max(max_len, L)\n",
        "                hist[bini(L)] += 1\n",
        "                if max_docs_per_lang and docs_seen >= max_docs_per_lang:\n",
        "                    break\n",
        "            if max_docs_per_lang and docs_seen >= max_docs_per_lang:\n",
        "                break\n",
        "        if total_tokens == 0:\n",
        "            print(f\"[metrics:{lang}] no tokens measured.\")\n",
        "            results[lang] = {\"bytes_per_token\": float(\"inf\")}\n",
        "            continue\n",
        "        bpt = total_bytes / total_tokens\n",
        "        var = (m2 / (docs_seen-1)) if docs_seen > 1 else 0.0\n",
        "        std = math.sqrt(var)\n",
        "        # approx percentiles from hist\n",
        "        def pct(p):\n",
        "            target = math.ceil(p*docs_seen); c=0\n",
        "            for i,cnt in enumerate(hist):\n",
        "                c += cnt\n",
        "                if c >= target: return bins[i]\n",
        "            return bins[-1]\n",
        "        p50,p90,p99 = pct(0.5), pct(0.9), pct(0.99)\n",
        "        byte_rate = byte_tok / max(1,total_tokens)\n",
        "        print(f\"[metrics:{lang}] docs={docs_seen:,} tokens={format_num(total_tokens)} bytes={format_num(total_bytes)}\")\n",
        "        print(f\"  - bytes/token = {bpt:.3f}\")\n",
        "        print(f\"  - len(tokens/doc): min={min_len} max={max_len} mean={mean:.1f} std={std:.1f} p50≈{p50} p90≈{p90} p99≈{p99}\")\n",
        "        print(f\"  - byte_fallback rate = {byte_rate*100:.3f}%\")\n",
        "        results[lang] = {\"docs_seen\":docs_seen,\"total_bytes\":int(total_bytes),\"total_tokens\":int(total_tokens),\n",
        "                         \"bytes_per_token\":float(bpt),\"len_min\":int(min_len),\"len_max\":int(max_len),\n",
        "                         \"len_mean\":float(mean),\"len_std\":float(std),\n",
        "                         \"len_p50_approx\":int(p50),\"len_p90_approx\":int(p90),\"len_p99_approx\":int(p99),\n",
        "                         \"byte_fallback_rate\":float(byte_rate)}\n",
        "    return results\n",
        "\n",
        "# ==== Pipeline =============================================================================\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "ensure_dir(OUT_DIR_DRIVE); ensure_dir(REPORTS_DIR_DRIVE)\n",
        "subset_path = \"/content/train_subset.txt\"\n",
        "\n",
        "# 1) Build byte-budgeted subset\n",
        "written, totals = build_byte_budget_subset(\n",
        "    DRIVE_SPLITS_DIR, DRIVE_RAW_DIR, LANGS,\n",
        "    TRAIN_BYTE_BUDGET_TOTAL, MAX_CHARS_PER_LINE,\n",
        "    USE_INDIC_PRETOK, USE_PLACEHOLDERS, ADD_LANG_TAGS,\n",
        "    out_file=subset_path\n",
        ")\n",
        "print(f\"[subset] wrote -> {subset_path} (mem={mem_mb()})\")\n",
        "\n",
        "# 2) Train & export per vocab\n",
        "tok_jsons=[]\n",
        "for vs in VOCAB_SIZES:\n",
        "    prefix = os.path.join(OUT_DIR_DRIVE, f\"sp_unigram_{vs}\")\n",
        "    model_path = prefix + \".model\"; vocab_path = prefix + \".vocab\"\n",
        "    train_sp_unigram(subset_path, prefix, vs)\n",
        "    export_hf(vocab_path, model_path, os.path.join(OUT_DIR_DRIVE, f\"sp_unigram_{vs}\"))\n",
        "    tok_jsons.append(os.path.join(OUT_DIR_DRIVE, f\"sp_unigram_{vs}\", \"tokenizer.json\"))\n",
        "\n",
        "    # 3) quick metrics on real files (streaming)\n",
        "    files_per_lang = {lang: pick_eval_files(lang, DRIVE_SPLITS_DIR, DRIVE_RAW_DIR) for lang in LANGS}\n",
        "    metrics = compute_metrics(model_path, files_per_lang, ANALYZE_DOCS_PER_LANG)\n",
        "\n",
        "    # 4) manifest\n",
        "    manifest = {\n",
        "        \"langs\": LANGS,\n",
        "        \"vocab_size\": vs,\n",
        "        \"character_coverage\": CHAR_COVERAGE,\n",
        "        \"use_indic_pretok\": USE_INDIC_PRETOK,\n",
        "        \"use_placeholders\": USE_PLACEHOLDERS,\n",
        "        \"add_lang_tags\": ADD_LANG_TAGS,\n",
        "        \"input_sentence_size\": INPUT_SENTENCE_SIZE,\n",
        "        \"seed_sentencepiece_size\": SEED_SENTENCEPIECE_SIZE,\n",
        "        \"num_sub_iterations\": NUM_SUB_ITERATIONS,\n",
        "        \"byte_budget_total\": TRAIN_BYTE_BUDGET_TOTAL,\n",
        "        \"max_chars_per_line\": MAX_CHARS_PER_LINE,\n",
        "        \"subset_bytes_per_lang\": totals,\n",
        "        \"subset_lines_per_lang\": written,\n",
        "        \"subset_path\": subset_path,\n",
        "        \"sp_model\": model_path,\n",
        "        \"hf_tokenizer_json\": os.path.join(OUT_DIR_DRIVE, f\"sp_unigram_{vs}\", \"tokenizer.json\"),\n",
        "        \"metrics\": metrics\n",
        "    }\n",
        "    mf_path = os.path.join(REPORTS_DIR_DRIVE, f\"tokenizer_manifest_sp{vs}.json\")\n",
        "    with open(mf_path,\"w\",encoding=\"utf-8\") as f:\n",
        "        json.dump(manifest, f, indent=2, ensure_ascii=False)\n",
        "    print(f\"[manifest] wrote {mf_path} | mem={mem_mb()}\")\n",
        "\n",
        "print(\"\\n[done] Artifacts:\", OUT_DIR_DRIVE)\n",
        "print(\"[done] Reports:\", REPORTS_DIR_DRIVE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TqGe5_7_nz-K",
        "outputId": "baad95ab-1d13-4cd5-86bd-234be184c935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[subset] byte budget total=120.00M (~UTF-8), per-lang≈40.00M\n",
            "[src:eng] /content/drive/MyDrive/LMA_SLM/data/splits/eng/train.jsonl\n",
            "[subset:eng] +25481 lines (pass 1) bytes=40.00M mem=1403.7 MB\n",
            "[src:hin] /content/drive/MyDrive/LMA_SLM/data/splits/hin/train.jsonl\n",
            "[subset:hin] +10826 lines (pass 1) bytes=40.00M mem=1506.3 MB\n",
            "[src:nep] /content/drive/MyDrive/LMA_SLM/data/splits/nep/train.jsonl\n",
            "[subset:nep] +11786 lines (pass 1) bytes=40.00M mem=1502.2 MB\n",
            "[src:eng] /content/drive/MyDrive/LMA_SLM/data/splits/eng/train.jsonl\n",
            "[src:hin] /content/drive/MyDrive/LMA_SLM/data/splits/hin/train.jsonl\n",
            "[src:nep] /content/drive/MyDrive/LMA_SLM/data/splits/nep/train.jsonl\n",
            "[subset] DONE per-lang bytes: {'eng': '40.00M', 'hin': '40.00M', 'nep': '40.00M'}\n",
            "[subset] lines written: {'eng': 25481, 'hin': 10826, 'nep': 11786}\n",
            "[subset] wrote -> /content/train_subset.txt (mem=1489.2 MB)\n",
            "[spm] train | vocab=48000 char_cov=0.9999 threads=4 iss=0\n",
            "[spm] wrote /content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_48000.model / .vocab | mem=1608.3 MB\n",
            "[hf] wrote /content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_48000/tokenizer.json (+sidecars)\n",
            "[metrics:eng] docs=8,000 tokens=5.12M bytes=21.24M\n",
            "  - bytes/token = 4.147\n",
            "  - len(tokens/doc): min=38 max=32576 mean=640.2 std=908.2 p50≈512 p90≈2048 p99≈4096\n",
            "  - byte_fallback rate = 0.246%\n",
            "[metrics:hin] docs=8,000 tokens=4.80M bytes=44.79M\n",
            "  - bytes/token = 9.327\n",
            "  - len(tokens/doc): min=5 max=172003 mean=600.2 std=2064.8 p50≈512 p90≈1024 p99≈4096\n",
            "  - byte_fallback rate = 0.232%\n",
            "[metrics:nep] docs=8,000 tokens=3.62M bytes=41.15M\n",
            "  - bytes/token = 11.366\n",
            "  - len(tokens/doc): min=33 max=10982 mean=452.6 std=560.8 p50≈512 p90≈1024 p99≈4096\n",
            "  - byte_fallback rate = 0.029%\n",
            "[manifest] wrote /content/drive/MyDrive/LMA_SLM/tokenizer_reports/tokenizer_manifest_sp48000.json | mem=1594.8 MB\n",
            "[spm] train | vocab=64000 char_cov=0.9999 threads=4 iss=0\n",
            "[spm] wrote /content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_64000.model / .vocab | mem=1638.2 MB\n",
            "[hf] wrote /content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_64000/tokenizer.json (+sidecars)\n",
            "[metrics:eng] docs=8,000 tokens=4.96M bytes=21.24M\n",
            "  - bytes/token = 4.284\n",
            "  - len(tokens/doc): min=35 max=31481 mean=619.6 std=877.9 p50≈512 p90≈2048 p99≈4096\n",
            "  - byte_fallback rate = 0.254%\n",
            "[metrics:hin] docs=8,000 tokens=4.68M bytes=44.79M\n",
            "  - bytes/token = 9.566\n",
            "  - len(tokens/doc): min=5 max=165213 mean=585.2 std=1986.3 p50≈512 p90≈1024 p99≈4096\n",
            "  - byte_fallback rate = 0.238%\n",
            "[metrics:nep] docs=8,000 tokens=3.50M bytes=41.15M\n",
            "  - bytes/token = 11.772\n",
            "  - len(tokens/doc): min=33 max=10489 mean=437.0 std=538.8 p50≈512 p90≈1024 p99≈4096\n",
            "  - byte_fallback rate = 0.031%\n",
            "[manifest] wrote /content/drive/MyDrive/LMA_SLM/tokenizer_reports/tokenizer_manifest_sp64000.json | mem=1584.3 MB\n",
            "\n",
            "[done] Artifacts: /content/drive/MyDrive/LMA_SLM/tokenizers\n",
            "[done] Reports: /content/drive/MyDrive/LMA_SLM/tokenizer_reports\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hi\")"
      ],
      "metadata": {
        "id": "iKjILJrENEU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ba491a-a22b-4762-bab2-ad6fd51f6be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================= Tokenizer & Data QA (no plots, RAM friendly) ===========================\n",
        "# What it does:\n",
        "# - Loads the SentencePiece model (.model) AND HF tokenizer.json (for consistency sanity checks)\n",
        "# - Streams each language's split files (val/train/raw fallbacks), no big arrays\n",
        "# - Computes:\n",
        "#     * bytes/token, token-length stats (min/mean/p50/p90/p99/max)\n",
        "#     * byte_fallback usage and which byte pieces are most frequent\n",
        "#     * placeholder coverage & correctness: <URL>, <EMAIL>, <NUM>, <DATE>\n",
        "#     * language tag coverage (<eng>/<hin>/<nep>) and position correctness (should be 1st)\n",
        "#     * special tokens integrity (<unk>, <s>, </s>)\n",
        "#     * character inventory coverage: which Unicode chars appear in data but only tokenize via bytes\n",
        "#     * “fertility”: tokens per whitespace-separated word; top over-segmented words\n",
        "#     * top-N pieces overall & per language, suspicious pieces (very short/long/whitespace)\n",
        "#     * round-trip encode→decode→encode consistency checks (sampled)\n",
        "#\n",
        "\n",
        "\n",
        "import os, io, json, re, math, gzip, lzma, unicodedata\n",
        "from collections import Counter, defaultdict\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "\n",
        "# ------------------------ CONFIG (edit paths if needed) -----------------------------------------\n",
        "# Point to the SAME drive locations you used earlier\n",
        "DRIVE_SPLITS_DIR = \"/content/drive/MyDrive/LMA_SLM/data/splits\"\n",
        "DRIVE_RAW_DIR    = \"/content/drive/MyDrive/LMA_SLM/data/raw\"      # optional fallback\n",
        "\n",
        "# Pick which tokenizer variant to inspect\n",
        "TOK_DIR = \"/content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_64000\"  # or sp_unigram_48000\n",
        "SPM_MODEL = \"/content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_64000.model\"\n",
        "\n",
        "# Languages present\n",
        "LANGS = [\"eng\", \"hin\", \"nep\"]\n",
        "LANG_TAGS = {\"eng\": \"<eng>\", \"hin\": \"<hin>\", \"nep\": \"<nep>\"}\n",
        "\n",
        "# Streaming/sample limits for analysis\n",
        "DOCS_PER_LANG = 8000                 # how many JSONL records to scan per language (val/train/raw combined)\n",
        "PRINT_TOP_N   = 40                   # how many top pieces/words to show\n",
        "MAX_CHARS_PER_LINE = 10000           # trim pathological lines to avoid skew\n",
        "\n",
        "# Regexes reused (same as training stage)\n",
        "_URL_RE   = re.compile(r'https?://\\S+')\n",
        "_EMAIL_RE = re.compile(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b')\n",
        "_DATE_RE  = re.compile(r'\\b\\d{1,4}([./-]\\d{1,2}){1,2}\\b')\n",
        "_NUM_RE   = re.compile(r'\\b\\d+\\b')\n",
        "\n",
        "PLACEHOLDERS = [\"<URL>\", \"<EMAIL>\", \"<NUM>\", \"<DATE>\"]\n",
        "SPECIALS     = [\"<unk>\", \"<s>\", \"</s>\"]\n",
        "\n",
        "# ------------------------------------------------------------------------------------------------\n",
        "\n",
        "# libs\n",
        "import sentencepiece as spm\n",
        "from tokenizers import Tokenizer\n",
        "\n",
        "try:\n",
        "    import zstandard as zstd\n",
        "except Exception:\n",
        "    zstd = None\n",
        "\n",
        "def _open_smart(path: str):\n",
        "    lower = path.lower()\n",
        "    if lower.endswith(\".gz\"):\n",
        "        return gzip.open(path, \"rb\")\n",
        "    if lower.endswith(\".xz\"):\n",
        "        return lzma.open(path, \"rb\")\n",
        "    if lower.endswith(\".zst\"):\n",
        "        if zstd is None:\n",
        "            raise RuntimeError(f\"zstandard needed for: {path}\")\n",
        "        dctx = zstd.ZstdDecompressor()\n",
        "        return dctx.stream_reader(open(path, \"rb\"))\n",
        "    return open(path, \"rb\")\n",
        "\n",
        "def jsonl_iter_texts(path: str, limit: Optional[int] = None,\n",
        "                     encoding: str = \"utf-8\", errors: str = \"replace\"):\n",
        "    \"\"\"Stream `text` field from JSONL; skips bad rows; trims very long lines.\"\"\"\n",
        "    bad = 0; n = 0\n",
        "    with _open_smart(path) as fb:\n",
        "        with io.TextIOWrapper(fb, encoding=encoding, errors=errors, newline=\"\") as f:\n",
        "            for raw in f:\n",
        "                s = raw.strip()\n",
        "                if not s: continue\n",
        "                try:\n",
        "                    rec = json.loads(s)\n",
        "                except Exception:\n",
        "                    bad += 1\n",
        "                    if bad <= 3:\n",
        "                        print(f\"[warn] bad JSON in {os.path.basename(path)} (#{bad})\")\n",
        "                    continue\n",
        "                t = rec.get(\"text\", \"\")\n",
        "                if not t: continue\n",
        "                if MAX_CHARS_PER_LINE and len(t) > MAX_CHARS_PER_LINE:\n",
        "                    t = t[:MAX_CHARS_PER_LINE]\n",
        "                yield t\n",
        "                n += 1\n",
        "                if limit and n >= limit:\n",
        "                    break\n",
        "\n",
        "def pick_eval_files(lang: str, splits_dir: str, raw_dir: str) -> List[str]:\n",
        "    cand = [\n",
        "        os.path.join(splits_dir, lang, \"val.jsonl\"),\n",
        "        os.path.join(splits_dir, lang, \"train.jsonl\"),\n",
        "        os.path.join(raw_dir, f\"{lang}.jsonl\"),\n",
        "    ]\n",
        "    seen, out = set(), []\n",
        "    for p in cand:\n",
        "        if os.path.exists(p) and p not in seen:\n",
        "            seen.add(p); out.append(p)\n",
        "    return out\n",
        "\n",
        "# ------------------------------- helpers ---------------------------------------------------------\n",
        "def format_num(n: float) -> str:\n",
        "    for unit, div in ((\"T\",1e12),(\"B\",1e9),(\"M\",1e6),(\"K\",1e3)):\n",
        "        if n >= div: return f\"{n/div:.2f}{unit}\"\n",
        "    return f\"{n:.0f}\"\n",
        "\n",
        "def _is_byte_piece(piece: str) -> bool:\n",
        "    return piece.startswith(\"<0x\") and piece.endswith(\">\")\n",
        "\n",
        "def tokens_per_word(sp: spm.SentencePieceProcessor, text: str) -> Tuple[int,int]:\n",
        "    \"\"\"Return (num_tokens, num_words) with a simple whitespace word split.\"\"\"\n",
        "    ids = sp.EncodeAsIds(text)\n",
        "    words = [w for w in text.split() if w]\n",
        "    return len(ids), len(words)\n",
        "\n",
        "def encode_decode_ok(sp: spm.SentencePieceProcessor, text: str) -> bool:\n",
        "    \"\"\"Round-trip check: encode->decode->encode produces same id sequence.\"\"\"\n",
        "    a = sp.EncodeAsIds(text)\n",
        "    d = sp.DecodeIds(a)\n",
        "    b = sp.EncodeAsIds(d)\n",
        "    return a == b\n",
        "\n",
        "def top_n(counter: Counter, n: int) -> List[Tuple[str,int]]:\n",
        "    return counter.most_common(n)\n",
        "\n",
        "# --------------------------- main analysis -------------------------------------------------------\n",
        "def analyze_tokenizer_and_data(\n",
        "    spm_model_path: str,\n",
        "    hf_tokenizer_json_dir: str,\n",
        "    langs: List[str],\n",
        "    splits_dir: str,\n",
        "    raw_dir: str,\n",
        "    docs_per_lang: int,\n",
        "    print_top_n: int\n",
        "):\n",
        "    print(f\"[load] SPM model: {spm_model_path}\")\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    sp.Load(spm_model_path)\n",
        "\n",
        "    hf_json = os.path.join(hf_tokenizer_json_dir, \"tokenizer.json\")\n",
        "    if os.path.exists(hf_json):\n",
        "        print(f\"[load] HF tokenizer: {hf_json}\")\n",
        "        tok_hf = Tokenizer.from_file(hf_json)\n",
        "    else:\n",
        "        tok_hf = None\n",
        "        print(\"[load] HF tokenizer.json not found (skipping HF-specific checks).\")\n",
        "\n",
        "    # ----- global vocab overview -----\n",
        "    vocab_size = sp.GetPieceSize()\n",
        "    pieces = [sp.IdToPiece(i) for i in range(vocab_size)]\n",
        "    byte_pieces = sum(1 for p in pieces if _is_byte_piece(p))\n",
        "    specials_present = {sp.IdToPiece(i) for i in range(min(10, vocab_size)) if sp.IdToPiece(i) in set(SPECIALS)}\n",
        "    lang_syms_present = [p for p in pieces if p in set(LANG_TAGS.values())]\n",
        "    placeholders_present = [p for p in pieces if p in set(PLACEHOLDERS)]\n",
        "\n",
        "    print(\"\\n[vocab]\")\n",
        "    print(f\"  - vocab_size={vocab_size}\")\n",
        "    print(f\"  - byte_pieces={byte_pieces}  (should be 256 when byte_fallback=True)\")\n",
        "    print(f\"  - specials found at low ids: {sorted(list(specials_present))}\")\n",
        "    print(f\"  - language tags present: {lang_syms_present}\")\n",
        "    print(f\"  - placeholders present: {placeholders_present}\")\n",
        "\n",
        "    # Identify suspicious pieces (leading/trailing space, all-punct, very long)\n",
        "    susp = []\n",
        "    for p in pieces:\n",
        "        if len(p) > 24:\n",
        "            susp.append((\"long\", p))\n",
        "        if p.strip() != p and p not in SPECIALS:\n",
        "            susp.append((\"spacey\", repr(p)))\n",
        "        if all(ch.isspace() or unicodedata.category(ch)[0] in (\"P\",\"S\") for ch in p) and p not in SPECIALS and not _is_byte_piece(p):\n",
        "            susp.append((\"punct/sym-only\", p))\n",
        "    if susp:\n",
        "        print(\"\\n[vocab suspicious pieces] (showing up to 20)\")\n",
        "        for k, p in susp[:20]:\n",
        "            print(f\"  - {k}: {p}\")\n",
        "    else:\n",
        "        print(\"\\n[vocab suspicious pieces] none\")\n",
        "\n",
        "    # ----- per-language streaming stats -----\n",
        "    overall_piece_freq = Counter()\n",
        "    per_lang_piece_freq: Dict[str, Counter] = {l: Counter() for l in langs}\n",
        "    byte_piece_freq = Counter()\n",
        "    word_overseg = Counter()  # words with high fertility\n",
        "\n",
        "    bins = [0,8,16,32,64,128,256,512,1024,2048,4096,8192,16384]\n",
        "    def bini(x):\n",
        "        for i,b in enumerate(bins):\n",
        "            if x <= b: return i\n",
        "        return len(bins)-1\n",
        "\n",
        "    print(\"\\n[per-language metrics]\")\n",
        "    per_lang_results = {}\n",
        "    for lang in langs:\n",
        "        files = pick_eval_files(lang, splits_dir, raw_dir)\n",
        "        if not files:\n",
        "            print(f\"  - {lang}: no files found; skipping.\")\n",
        "            continue\n",
        "\n",
        "        docs = 0\n",
        "        total_bytes = total_tokens = 0\n",
        "        min_len = 10**9; max_len = 0; mean = 0.0; m2 = 0.0\n",
        "        hist = [0]*len(bins)\n",
        "        byte_tok = 0\n",
        "\n",
        "        # coverage checks\n",
        "        char_inventory = Counter()\n",
        "        byte_only_chars = Counter()  # chars for which all pieces were byte_fallback\n",
        "        placeholder_hits = Counter()\n",
        "        lang_tag_ok = 0\n",
        "        roundtrip_ok = 0\n",
        "        roundtrip_bad = 0\n",
        "\n",
        "        for p in files:\n",
        "            for text in jsonl_iter_texts(p, limit=None):\n",
        "                # Keep character inventory\n",
        "                char_inventory.update(list(text))\n",
        "\n",
        "                # Placeholders present?\n",
        "                ph = {\n",
        "                    \"<URL>\": bool(_URL_RE.search(text)),\n",
        "                    \"<EMAIL>\": bool(_EMAIL_RE.search(text)),\n",
        "                    \"<DATE>\": bool(_DATE_RE.search(text)),\n",
        "                    \"<NUM>\": bool(_NUM_RE.search(text)),\n",
        "                }\n",
        "                for k,v in ph.items():\n",
        "                    if v: placeholder_hits[k] += 1\n",
        "\n",
        "                ids = sp.EncodeAsIds(text)\n",
        "                L = len(ids)\n",
        "                total_bytes += len(text.encode(\"utf-8\"))\n",
        "                total_tokens += L\n",
        "                min_len = min(min_len, L); max_len = max(max_len, L)\n",
        "                d = L - mean; mean += d / (docs+1); m2 += d*(L-mean)\n",
        "                hist[bini(L)] += 1\n",
        "                docs += 1\n",
        "\n",
        "                # piece frequencies\n",
        "                for tid in ids:\n",
        "                    piece = sp.IdToPiece(tid)\n",
        "                    overall_piece_freq[piece] += 1\n",
        "                    per_lang_piece_freq[lang][piece] += 1\n",
        "                    if _is_byte_piece(piece):\n",
        "                        byte_tok += 1\n",
        "\n",
        "                # language tag correctness (first token)\n",
        "                pieces_this = [sp.IdToPiece(tid) for tid in ids[:2]]  # first couple tokens\n",
        "                if LANG_TAGS.get(lang) in pieces_this[:1]:\n",
        "                    lang_tag_ok += 1\n",
        "\n",
        "                # fertility (tokens per whitespace word)\n",
        "                t_count, w_count = tokens_per_word(sp, text)\n",
        "                if w_count > 0:\n",
        "                    # crude average; flag extreme ratios\n",
        "                    fert = t_count / w_count\n",
        "                    if fert > 4.0 and w_count >= 4:\n",
        "                        # store a few culprit words by over-segmentation\n",
        "                        for w in text.split():\n",
        "                            if len(w) >= 6:\n",
        "                                # re-encode word alone\n",
        "                                wl = len(sp.EncodeAsIds(w))\n",
        "                                if wl >= 5:\n",
        "                                    word_overseg[w.lower()] += 1\n",
        "\n",
        "                # round-trip check (sample ~1 in 50 docs)\n",
        "                if (docs % 50) == 1:\n",
        "                    if encode_decode_ok(sp, text):\n",
        "                        roundtrip_ok += 1\n",
        "                    else:\n",
        "                        roundtrip_bad += 1\n",
        "\n",
        "                if docs_per_lang and docs >= docs_per_lang:\n",
        "                    break\n",
        "            if docs_per_lang and docs >= docs_per_lang:\n",
        "                break\n",
        "\n",
        "        if total_tokens == 0:\n",
        "            print(f\"  - {lang}: no tokens collected\")\n",
        "            continue\n",
        "\n",
        "        bpt = total_bytes / total_tokens\n",
        "        var = (m2 / (docs-1)) if docs > 1 else 0.0\n",
        "        std = math.sqrt(var)\n",
        "        def pct(pp):\n",
        "            target = math.ceil(pp*docs); c=0\n",
        "            for i,cnt in enumerate(hist):\n",
        "                c += cnt\n",
        "                if c >= target: return bins[i]\n",
        "            return bins[-1]\n",
        "        p50,p90,p99 = pct(0.5), pct(0.9), pct(0.99)\n",
        "        byte_rate = byte_tok / max(1,total_tokens)\n",
        "\n",
        "        # which chars require byte fallback?\n",
        "        # We approximate: if any piece for that char is a non-byte piece, it's \"covered\".\n",
        "        covered_chars = set()\n",
        "        for ch, cnt in char_inventory.items():\n",
        "            # encode single char and see if any non-byte piece appears\n",
        "            ids_ch = sp.EncodeAsIds(ch)\n",
        "            if any(not _is_byte_piece(sp.IdToPiece(tid)) for tid in ids_ch):\n",
        "                covered_chars.add(ch)\n",
        "        for ch, cnt in char_inventory.items():\n",
        "            if ch not in covered_chars:\n",
        "                byte_only_chars[ch] += cnt\n",
        "\n",
        "        print(f\"\\n  [{lang}] docs={docs:,} tokens={format_num(total_tokens)} bytes={format_num(total_bytes)}\")\n",
        "        print(f\"    - bytes/token = {bpt:.3f}  | byte_fallback rate = {byte_rate*100:.3f}%\")\n",
        "        print(f\"    - len(tokens/doc): min={min_len} max={max_len} mean={mean:.1f} std={std:.1f} p50≈{p50} p90≈{p90} p99≈{p99}\")\n",
        "        print(f\"    - lang tag first-token OK in {lang_tag_ok}/{docs} docs ({lang_tag_ok/docs*100:.1f}%)\")\n",
        "        if roundtrip_ok+roundtrip_bad > 0:\n",
        "            print(f\"    - round-trip checks: ok={roundtrip_ok} bad={roundtrip_bad}  (target: 100% ok; some bad is usually data noise)\")\n",
        "\n",
        "        ph_total_docs = max(1, docs)\n",
        "        for ph in PLACEHOLDERS:\n",
        "            if placeholder_hits[ph]:\n",
        "                print(f\"    - placeholder '{ph}' seen in {placeholder_hits[ph]} docs \"\n",
        "                      f\"({placeholder_hits[ph]/ph_total_docs*100:.2f}%); \"\n",
        "                      f\"inspect tokens manually if suspicious.\")\n",
        "\n",
        "        # Save for summary\n",
        "        per_lang_results[lang] = {\n",
        "            \"docs\": docs,\n",
        "            \"bytes\": total_bytes,\n",
        "            \"tokens\": total_tokens,\n",
        "            \"bytes_per_token\": bpt,\n",
        "            \"byte_fallback_rate\": byte_rate,\n",
        "            \"len_min\": min_len, \"len_max\": max_len,\n",
        "            \"len_mean\": mean, \"len_std\": std,\n",
        "            \"len_p50\": p50, \"len_p90\": p90, \"len_p99\": p99,\n",
        "            \"lang_tag_first_ok\": lang_tag_ok,\n",
        "            \"roundtrip_ok\": roundtrip_ok, \"roundtrip_bad\": roundtrip_bad,\n",
        "        }\n",
        "\n",
        "        # top pieces for this lang (excluding byte pieces for readability)\n",
        "        top_lang = [(p,c) for p,c in per_lang_piece_freq[lang].most_common() if not _is_byte_piece(p)]\n",
        "        print(f\"    - top pieces (no-bytes) [{lang}] top{min(print_top_n, len(top_lang))}:\")\n",
        "        for p,c in top_lang[:print_top_n]:\n",
        "            print(f\"        {p}\\t{c}\")\n",
        "\n",
        "        # frequent byte pieces (if any)\n",
        "        for p,c in per_lang_piece_freq[lang].most_common():\n",
        "            if _is_byte_piece(p):\n",
        "                byte_piece_freq[p] += c\n",
        "\n",
        "        # top byte-only chars (bad if common)\n",
        "        if byte_only_chars:\n",
        "            top_boc = sorted(byte_only_chars.items(), key=lambda kv: kv[1], reverse=True)[:10]\n",
        "            print(f\"    - chars falling back to bytes (top 10):\")\n",
        "            for ch, cnt in top_boc:\n",
        "                name = unicodedata.name(ch, \"UNKNOWN\")\n",
        "                cp = f\"U+{ord(ch):04X}\"\n",
        "                printable = ch if not ch.isspace() else repr(ch)\n",
        "                print(f\"        {printable} ({cp} {name}) x{cnt}\")\n",
        "\n",
        "        # worst over-segmented words (heuristic)\n",
        "        if word_overseg:\n",
        "            print(f\"    - over-segmentation suspects (words often split into >=5 tokens):\")\n",
        "            for w, c in word_overseg.most_common(10):\n",
        "                print(f\"        {w}\\t{c}\")\n",
        "\n",
        "    # ----- global top pieces overall -----\n",
        "    print(\"\\n[top pieces overall (no-bytes)]\")\n",
        "    for p,c in [(p,c) for p,c in overall_piece_freq.most_common() if not _is_byte_piece(p)][:print_top_n]:\n",
        "        print(f\"  {p}\\t{c}\")\n",
        "\n",
        "    if byte_piece_freq:\n",
        "        print(\"\\n[top byte pieces overall]\")\n",
        "        for p,c in byte_piece_freq.most_common(20):\n",
        "            print(f\"  {p}\\t{c}\")\n",
        "\n",
        "    # ----- HF cross-checks (optional) -----\n",
        "    if tok_hf:\n",
        "        print(\"\\n[HF cross-check]\")\n",
        "        sample = \" \".join([LANG_TAGS.get(\"hin\",\"<hin>\"), \"नमस्ते\", \"world!\", \"<URL>\", \"2024-01-01\", \"<EMAIL>\", \"<NUM> 42\"])\n",
        "        ids_sp = sp.EncodeAsIds(sample)\n",
        "        ids_hf = tok_hf.encode(sample).ids\n",
        "        print(f\"  - sample: {sample}\")\n",
        "        print(f\"  - SPM ids: {len(ids_sp)} tokens\")\n",
        "        print(f\"  - HF  ids: {len(ids_hf)} tokens\")\n",
        "        if len(ids_sp) != len(ids_hf):\n",
        "            print(\"  [warn] HF vs SPM token counts differ. Acceptable if HF normalizer differs; inspect if large.\")\n",
        "        else:\n",
        "            print(\"  [ok] HF and SPM agree on token count for sample.\")\n",
        "\n",
        "    # ----- summary JSON to reports dir -----\n",
        "    reports_dir = \"/content/drive/MyDrive/LMA_SLM/tokenizer_reports\"\n",
        "    os.makedirs(reports_dir, exist_ok=True)\n",
        "    out_summary = os.path.join(reports_dir, \"tokenizer_data_QA_summary.json\")\n",
        "    with open(out_summary, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\n",
        "            \"tokenizer_dir\": hf_tokenizer_json_dir,\n",
        "            \"spm_model\": spm_model_path,\n",
        "            \"per_language\": per_lang_results,\n",
        "            \"top_pieces_overall\": top_n(overall_piece_freq, print_top_n),\n",
        "            \"top_byte_pieces\": top_n(byte_piece_freq, min(20, len(byte_piece_freq))),\n",
        "            \"specials_present\": list(sorted(specials_present)) if 'specials_present' in locals() else [],\n",
        "            \"placeholders_present\": placeholders_present,\n",
        "            \"lang_tags_present\": lang_syms_present\n",
        "        }, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"\\n[done] wrote summary -> {out_summary}\")\n",
        "\n",
        "# --------------------------- run ---------------------------------------------------------------\n",
        "analyze_tokenizer_and_data(\n",
        "    spm_model_path=SPM_MODEL,\n",
        "    hf_tokenizer_json_dir=TOK_DIR,\n",
        "    langs=LANGS,\n",
        "    splits_dir=DRIVE_SPLITS_DIR,\n",
        "    raw_dir=DRIVE_RAW_DIR,\n",
        "    docs_per_lang=DOCS_PER_LANG,\n",
        "    print_top_n=PRINT_TOP_N\n",
        ")\n",
        "# ==============================================================================================="
      ],
      "metadata": {
        "id": "mMkyDOgBGo00",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c043e8-c752-4b41-9b16-9700105f54ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load] SPM model: /content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_64000.model\n",
            "[load] HF tokenizer: /content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_64000/tokenizer.json\n",
            "\n",
            "[vocab]\n",
            "  - vocab_size=64000\n",
            "  - byte_pieces=256  (should be 256 when byte_fallback=True)\n",
            "  - specials found at low ids: ['</s>', '<s>', '<unk>']\n",
            "  - language tags present: ['<eng>', '<hin>', '<nep>']\n",
            "  - placeholders present: ['<URL>', '<EMAIL>', '<NUM>', '<DATE>']\n",
            "\n",
            "[vocab suspicious pieces] (showing up to 20)\n",
            "  - punct/sym-only: ▁\n",
            "  - punct/sym-only: <▁\n",
            "  - punct/sym-only: .▁\n",
            "  - punct/sym-only: -▁\n",
            "  - punct/sym-only: '▁\n",
            "  - punct/sym-only: ।▁\n",
            "  - punct/sym-only: ’▁\n",
            "  - punct/sym-only: (▁\n",
            "  - punct/sym-only: \"▁\n",
            "  - punct/sym-only: “▁\n",
            "  - punct/sym-only: )▁\n",
            "  - punct/sym-only: :▁\n",
            "  - punct/sym-only: ?▁\n",
            "  - punct/sym-only: ,▁\n",
            "  - punct/sym-only: ‘▁\n",
            "  - punct/sym-only: !▁\n",
            "  - punct/sym-only: ...▁\n",
            "  - punct/sym-only: ·\n",
            "  - punct/sym-only: ÷\n",
            "  - punct/sym-only: °\n",
            "\n",
            "[per-language metrics]\n",
            "\n",
            "  [eng] docs=8,000 tokens=4.58M bytes=19.63M\n",
            "    - bytes/token = 4.285  | byte_fallback rate = 0.241%\n",
            "    - len(tokens/doc): min=35 max=5047 mean=572.7 std=493.4 p50≈512 p90≈2048 p99≈4096\n",
            "    - lang tag first-token OK in 0/8000 docs (0.0%)\n",
            "    - round-trip checks: ok=160 bad=0  (target: 100% ok; some bad is usually data noise)\n",
            "    - placeholder '<URL>' seen in 70 docs (0.88%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<EMAIL>' seen in 33 docs (0.41%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<NUM>' seen in 6847 docs (85.59%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<DATE>' seen in 1819 docs (22.74%); inspect tokens manually if suspicious.\n",
            "    - top pieces (no-bytes) [eng] top40:\n",
            "        the▁\t177894\n",
            "        .▁\t163257\n",
            "        ,▁\t152880\n",
            "        to▁\t84616\n",
            "        of▁\t82655\n",
            "        and▁\t81664\n",
            "        a▁\t70153\n",
            "        in▁\t64912\n",
            "        ▁\t47037\n",
            "        s\t44418\n",
            "        -\t38242\n",
            "        s▁\t35972\n",
            "        is▁\t35639\n",
            "        for▁\t31869\n",
            "        on▁\t28392\n",
            "        that▁\t28065\n",
            "        The▁\t26014\n",
            "        '\t23510\n",
            "        with▁\t23448\n",
            "        as▁\t18935\n",
            "        ’\t18329\n",
            "        was▁\t17524\n",
            "        (\t17386\n",
            "        be▁\t17228\n",
            "        has▁\t16127\n",
            "        at▁\t15718\n",
            "        are▁\t15347\n",
            "        by▁\t14840\n",
            "        from▁\t14759\n",
            "        it▁\t14630\n",
            "        have▁\t14069\n",
            "        will▁\t14052\n",
            "        an▁\t12557\n",
            "        )▁\t12417\n",
            "        his▁\t12413\n",
            "        this▁\t11667\n",
            "        :▁\t11362\n",
            "        you▁\t10902\n",
            "        d\t10899\n",
            "        he▁\t10638\n",
            "    - chars falling back to bytes (top 10):\n",
            "        ' ' (U+0020 SPACE) x3213349\n",
            "        '\\n' (U+000A UNKNOWN) x86069\n",
            "        � (U+FFFD REPLACEMENT CHARACTER) x3\n",
            "        ‌ (U+200C ZERO WIDTH NON-JOINER) x2\n",
            "    - over-segmentation suspects (words often split into >=5 tokens):\n",
            "        şöbəsinin\t8\n",
            "        müalicə\t8\n",
            "        hüceyrəli\t8\n",
            "        tərəfindən\t5\n",
            "        xəstənin\t5\n",
            "        hüceyrələri\t5\n",
            "        keçmiş\t5\n",
            "        vəzifədən\t4\n",
            "        edilərək\t4\n",
            "        zəhərli\t4\n",
            "\n",
            "  [hin] docs=8,000 tokens=4.26M bytes=40.93M\n",
            "    - bytes/token = 9.612  | byte_fallback rate = 0.232%\n",
            "    - len(tokens/doc): min=5 max=4341 mean=532.2 std=494.2 p50≈512 p90≈1024 p99≈4096\n",
            "    - lang tag first-token OK in 0/8000 docs (0.0%)\n",
            "    - round-trip checks: ok=160 bad=0  (target: 100% ok; some bad is usually data noise)\n",
            "    - placeholder '<URL>' seen in 30 docs (0.38%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<EMAIL>' seen in 7 docs (0.09%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<NUM>' seen in 6377 docs (79.71%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<DATE>' seen in 1097 docs (13.71%); inspect tokens manually if suspicious.\n",
            "    - top pieces (no-bytes) [hin] top40:\n",
            "        ।▁\t134426\n",
            "        के▁\t127719\n",
            "        में▁\t91151\n",
            "        ,▁\t82373\n",
            "        ▁\t75853\n",
            "        की▁\t72637\n",
            "        है\t64212\n",
            "        को▁\t55357\n",
            "        से▁\t55124\n",
            "        और▁\t51285\n",
            "        का▁\t45029\n",
            "        ने▁\t40998\n",
            "        .▁\t35687\n",
            "        पर▁\t32501\n",
            "        है▁\t30854\n",
            "        कि▁\t28189\n",
            "        हैं\t25391\n",
            "        भी▁\t24534\n",
            "        एक▁\t22468\n",
            "        कर▁\t20334\n",
            "        -\t20298\n",
            "        लिए▁\t19794\n",
            "        इस▁\t19378\n",
            "        नहीं▁\t16961\n",
            "        ही▁\t16333\n",
            "        ों▁\t14744\n",
            "        यह▁\t14161\n",
            "        हो▁\t13688\n",
            "        )▁\t12869\n",
            "        किया▁\t12831\n",
            "        (\t12491\n",
            "        तो▁\t11996\n",
            "        करने▁\t11704\n",
            "        साथ▁\t10965\n",
            "        -▁\t10263\n",
            "        न▁\t9382\n",
            "        हैं▁\t9351\n",
            "        था\t9206\n",
            "        गया▁\t9179\n",
            "        ग\t8748\n",
            "    - chars falling back to bytes (top 10):\n",
            "        ' ' (U+0020 SPACE) x3129967\n",
            "        '\\n' (U+000A UNKNOWN) x57479\n",
            "        � (U+FFFD REPLACEMENT CHARACTER) x2\n",
            "        ​ (U+200B ZERO WIDTH SPACE) x1\n",
            "    - over-segmentation suspects (words often split into >=5 tokens):\n",
            "        şöbəsinin\t8\n",
            "        müalicə\t8\n",
            "        hüceyrəli\t8\n",
            "        tərəfindən\t5\n",
            "        xəstənin\t5\n",
            "        hüceyrələri\t5\n",
            "        keçmiş\t5\n",
            "        vəzifədən\t4\n",
            "        edilərək\t4\n",
            "        zəhərli\t4\n",
            "\n",
            "  [nep] docs=8,000 tokens=3.39M bytes=39.95M\n",
            "    - bytes/token = 11.797  | byte_fallback rate = 0.031%\n",
            "    - len(tokens/doc): min=33 max=3270 mean=423.3 std=442.9 p50≈512 p90≈1024 p99≈4096\n",
            "    - lang tag first-token OK in 0/8000 docs (0.0%)\n",
            "    - round-trip checks: ok=160 bad=0  (target: 100% ok; some bad is usually data noise)\n",
            "    - placeholder '<URL>' seen in 13 docs (0.16%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<EMAIL>' seen in 34 docs (0.43%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<NUM>' seen in 6948 docs (86.85%); inspect tokens manually if suspicious.\n",
            "    - placeholder '<DATE>' seen in 971 docs (12.14%); inspect tokens manually if suspicious.\n",
            "    - top pieces (no-bytes) [nep] top40:\n",
            "        ।▁\t143951\n",
            "        ▁\t98451\n",
            "        ,▁\t63187\n",
            "        को▁\t48855\n",
            "        र▁\t47506\n",
            "        मा▁\t34771\n",
            "        छ▁\t31137\n",
            "        का▁\t25614\n",
            "        ले▁\t23921\n",
            "        १\t23626\n",
            "        छ\t23186\n",
            "        २\t21091\n",
            "        पनि▁\t20994\n",
            "        लाई▁\t16563\n",
            "        भएको▁\t15169\n",
            "        लागि▁\t12626\n",
            "        गरेको▁\t12392\n",
            "        ५\t12084\n",
            "        गर्न▁\t11869\n",
            "        छन्▁\t11780\n",
            "        यो▁\t11770\n",
            "        '\t11485\n",
            "        ३\t11078\n",
            "        ७\t9813\n",
            "        बाट▁\t9728\n",
            "        न\t9714\n",
            "        ४\t9707\n",
            "        ०▁\t9646\n",
            "        एक▁\t9460\n",
            "        -\t9138\n",
            "        गर्ने▁\t9034\n",
            "        ६\t8796\n",
            "        हो▁\t8723\n",
            "        भने▁\t8383\n",
            "        तथा▁\t8317\n",
            "        ०\t7920\n",
            "        नै▁\t7646\n",
            "        '▁\t7632\n",
            "        ९\t7508\n",
            "        छन्\t7179\n",
            "    - chars falling back to bytes (top 10):\n",
            "        ' ' (U+0020 SPACE) x2308420\n",
            "        '\\n' (U+000A UNKNOWN) x53218\n",
            "        '\\t' (U+0009 UNKNOWN) x2\n",
            "        ‎ (U+200E LEFT-TO-RIGHT MARK) x1\n",
            "    - over-segmentation suspects (words often split into >=5 tokens):\n",
            "        şöbəsinin\t8\n",
            "        müalicə\t8\n",
            "        hüceyrəli\t8\n",
            "        tərəfindən\t5\n",
            "        xəstənin\t5\n",
            "        hüceyrələri\t5\n",
            "        keçmiş\t5\n",
            "        vəzifədən\t4\n",
            "        edilərək\t4\n",
            "        zəhərli\t4\n",
            "\n",
            "[top pieces overall (no-bytes)]\n",
            "  ,▁\t298440\n",
            "  ।▁\t278623\n",
            "  ▁\t221341\n",
            "  .▁\t203212\n",
            "  the▁\t179004\n",
            "  के▁\t130631\n",
            "  को▁\t104317\n",
            "  में▁\t91386\n",
            "  to▁\t85111\n",
            "  of▁\t83482\n",
            "  and▁\t82287\n",
            "  की▁\t75344\n",
            "  का▁\t70753\n",
            "  a▁\t70715\n",
            "  -\t67678\n",
            "  in▁\t65581\n",
            "  है\t64649\n",
            "  से▁\t55529\n",
            "  र▁\t54051\n",
            "  और▁\t51419\n",
            "  s\t45808\n",
            "  ने▁\t44859\n",
            "  '\t41945\n",
            "  s▁\t36454\n",
            "  is▁\t35944\n",
            "  (\t35791\n",
            "  मा▁\t35547\n",
            "  पर▁\t32859\n",
            "  for▁\t32044\n",
            "  एक▁\t31969\n",
            "  छ▁\t31254\n",
            "  है▁\t31090\n",
            "  कि▁\t30847\n",
            "  )▁\t29966\n",
            "  on▁\t28683\n",
            "  that▁\t28201\n",
            "  १\t27764\n",
            "  ले▁\t26527\n",
            "  The▁\t26132\n",
            "  हैं\t25448\n",
            "\n",
            "[top byte pieces overall]\n",
            "  <0x25>\t3056\n",
            "  <0xE0>\t2643\n",
            "  <0xD0>\t977\n",
            "  <0xE2>\t951\n",
            "  <0xA4>\t766\n",
            "  <0x80>\t656\n",
            "  <0xA5>\t647\n",
            "  <0xB0>\t532\n",
            "  <0xC2>\t433\n",
            "  <0x3D>\t416\n",
            "  <0xD1>\t414\n",
            "  <0xD8>\t413\n",
            "  <0xAA>\t399\n",
            "  <0xBD>\t398\n",
            "  <0x82>\t391\n",
            "  <0xA2>\t385\n",
            "  <0xB3>\t314\n",
            "  <0xB9>\t312\n",
            "  <0x92>\t289\n",
            "  <0xAC>\t253\n",
            "\n",
            "[HF cross-check]\n",
            "  - sample: <hin> नमस्ते world! <URL> 2024-01-01 <EMAIL> <NUM> 42\n",
            "  - SPM ids: 21 tokens\n",
            "  - HF  ids: 19 tokens\n",
            "  [warn] HF vs SPM token counts differ. Acceptable if HF normalizer differs; inspect if large.\n",
            "\n",
            "[done] wrote summary -> /content/drive/MyDrive/LMA_SLM/tokenizer_reports/tokenizer_data_QA_summary.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================= Fast Token Counts per Language (SSD + Batching + Checkpoints) =======================\n",
        "import os, io, json, shutil, time, gzip, lzma\n",
        "from typing import List, Optional, Tuple\n",
        "import sentencepiece as spm\n",
        "\n",
        "# --------- CONFIG (edit paths if needed) ----------\n",
        "DRIVE_SPLITS_DIR = \"/content/drive/MyDrive/LMA_SLM/data/splits\"\n",
        "DRIVE_RAW_DIR    = \"/content/drive/MyDrive/LMA_SLM/data/raw\"   # fallback if split missing\n",
        "SPM_MODEL        = \"/content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_64000.model\"\n",
        "\n",
        "LANGS = [\"eng\", \"hin\", \"nep\"]\n",
        "\n",
        "# Performance knobs\n",
        "BATCH_LINES      = 4000     # lines per encode batch (increase if RAM allows)\n",
        "REPORT_EVERY_TOK = 2_000_000\n",
        "REPORT_EVERY_SEC = 30\n",
        "COPY_TO_LOCAL    = True     # True = copy Drive files to /content first (recommended)\n",
        "\n",
        "# Checkpointing\n",
        "CKPT_DIR = \"/content/token_count_ckpts\"\n",
        "os.makedirs(CKPT_DIR, exist_ok=True)\n",
        "\n",
        "# ------------ helpers ------------\n",
        "try:\n",
        "    import zstandard as zstd\n",
        "except Exception:\n",
        "    zstd = None\n",
        "\n",
        "def _open_smart(path: str):\n",
        "    lower = path.lower()\n",
        "    if lower.endswith(\".gz\"):\n",
        "        return gzip.open(path, \"rb\")\n",
        "    if lower.endswith(\".xz\"):\n",
        "        return lzma.open(path, \"rb\")\n",
        "    if lower.endswith(\".zst\"):\n",
        "        if zstd is None:\n",
        "            raise RuntimeError(\"zstandard needed for .zst files\")\n",
        "        dctx = zstd.ZstdDecompressor()\n",
        "        return dctx.stream_reader(open(path, \"rb\"))\n",
        "    return open(path, \"rb\")\n",
        "\n",
        "def pick_files_for_lang(lang: str) -> List[str]:\n",
        "    cand = [\n",
        "        os.path.join(DRIVE_SPLITS_DIR, lang, \"val.jsonl\"),\n",
        "        os.path.join(DRIVE_SPLITS_DIR, lang, \"train.jsonl\"),\n",
        "        os.path.join(DRIVE_RAW_DIR, f\"{lang}.jsonl\"),\n",
        "    ]\n",
        "    seen, out = set(), []\n",
        "    for p in cand:\n",
        "        if os.path.exists(p) and p not in seen:\n",
        "            seen.add(p); out.append(p)\n",
        "    return out\n",
        "\n",
        "def copy_to_local_if_needed(files: List[str], lang: str) -> List[str]:\n",
        "    if not COPY_TO_LOCAL:\n",
        "        return files\n",
        "    dst_root = f\"/content/token_count_local/{lang}\"\n",
        "    os.makedirs(dst_root, exist_ok=True)\n",
        "    local_files = []\n",
        "    for src in files:\n",
        "        dst = os.path.join(dst_root, os.path.basename(src))\n",
        "        if not os.path.exists(dst):\n",
        "            print(f\"[copy:{lang}] {src} -> {dst}\")\n",
        "            shutil.copy2(src, dst)\n",
        "        local_files.append(dst)\n",
        "    return local_files\n",
        "\n",
        "def load_ckpt(lang: str) -> dict:\n",
        "    path = os.path.join(CKPT_DIR, f\"{lang}.json\")\n",
        "    if os.path.exists(path):\n",
        "        try:\n",
        "            with open(path, \"r\") as f:\n",
        "                return json.load(f)\n",
        "        except Exception:\n",
        "            pass\n",
        "    return {\"files_done\": {}, \"tokens\": 0, \"docs\": 0, \"lines\": 0}\n",
        "\n",
        "def save_ckpt(lang: str, ck: dict):\n",
        "    path = os.path.join(CKPT_DIR, f\"{lang}.json\")\n",
        "    with open(path, \"w\") as f:\n",
        "        json.dump(ck, f)\n",
        "\n",
        "def iter_jsonl_texts(path: str):\n",
        "    with _open_smart(path) as fb:\n",
        "        with io.TextIOWrapper(fb, encoding=\"utf-8\", errors=\"replace\", newline=\"\") as f:\n",
        "            for raw in f:\n",
        "                s = raw.strip()\n",
        "                if not s:\n",
        "                    continue\n",
        "                try:\n",
        "                    rec = json.loads(s)\n",
        "                except Exception:\n",
        "                    continue\n",
        "                t = rec.get(\"text\", \"\")\n",
        "                if t:\n",
        "                    yield t\n",
        "\n",
        "def encode_batch_count(sp: spm.SentencePieceProcessor, lines: List[str]) -> int:\n",
        "    # Joining with a space keeps token totals exact (SPM is context-free across whitespace boundaries).\n",
        "    text = \" \".join(lines)\n",
        "    return len(sp.EncodeAsIds(text))\n",
        "\n",
        "# ------------ main ------------\n",
        "print(f\"[load] SentencePiece model: {SPM_MODEL}\")\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load(SPM_MODEL)\n",
        "\n",
        "lang_token_counts = {}\n",
        "grand_total = 0\n",
        "\n",
        "for lang in LANGS:\n",
        "    files = pick_files_for_lang(lang)\n",
        "    if not files:\n",
        "        print(f\"[skip] no files for {lang}\")\n",
        "        continue\n",
        "\n",
        "    files = copy_to_local_if_needed(files, lang)\n",
        "    ck = load_ckpt(lang)\n",
        "\n",
        "    tok_count = ck[\"tokens\"]\n",
        "    doc_count = ck[\"docs\"]\n",
        "    line_count = ck[\"lines\"]\n",
        "\n",
        "    print(f\"\\n=== [{lang}] starting from checkpoint: tokens={tok_count:,}, docs={doc_count:,}, lines={line_count:,} ===\")\n",
        "    t0 = time.time()\n",
        "    last_report_t = t0\n",
        "    last_report_tok = tok_count\n",
        "\n",
        "    for fp in files:\n",
        "        # skip file if already fully processed with same size\n",
        "        done_info = ck[\"files_done\"].get(fp)\n",
        "        sz = None\n",
        "        try:\n",
        "            sz = os.path.getsize(fp)\n",
        "        except OSError:\n",
        "            pass\n",
        "        if done_info and done_info.get(\"size\") == sz and done_info.get(\"done\", False):\n",
        "            print(f\"[{lang}] skip (done) {os.path.basename(fp)}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"[{lang}] counting {os.path.basename(fp)} ({sz if sz is not None else 'size?' } bytes)\")\n",
        "        batch = []\n",
        "        for text in iter_jsonl_texts(fp):\n",
        "            # count every JSONL record as a \"doc\"\n",
        "            doc_count += 1\n",
        "            batch.append(text)\n",
        "            if len(batch) >= BATCH_LINES:\n",
        "                tok_count += encode_batch_count(sp, batch)\n",
        "                line_count += len(batch)\n",
        "                batch.clear()\n",
        "\n",
        "                # progress report\n",
        "                now = time.time()\n",
        "                if tok_count - last_report_tok >= REPORT_EVERY_TOK or (now - last_report_t) >= REPORT_EVERY_SEC:\n",
        "                    dt = now - last_report_t\n",
        "                    speed = (tok_count - last_report_tok) / max(1e-6, dt)\n",
        "                    print(f\"    [{lang}] progress: tokens={tok_count:,} docs={doc_count:,} lines={line_count:,} ~{int(speed):,} tok/s\")\n",
        "                    last_report_t = now\n",
        "                    last_report_tok = tok_count\n",
        "                    # checkpoint\n",
        "                    ck[\"tokens\"] = tok_count; ck[\"docs\"] = doc_count; ck[\"lines\"] = line_count\n",
        "                    ck[\"files_done\"][fp] = {\"size\": sz, \"done\": False}\n",
        "                    save_ckpt(lang, ck)\n",
        "\n",
        "        if batch:\n",
        "            tok_count += encode_batch_count(sp, batch)\n",
        "            line_count += len(batch)\n",
        "            batch.clear()\n",
        "\n",
        "        # mark file done in ckpt\n",
        "        ck[\"tokens\"] = tok_count; ck[\"docs\"] = doc_count; ck[\"lines\"] = line_count\n",
        "        ck[\"files_done\"][fp] = {\"size\": sz, \"done\": True}\n",
        "        save_ckpt(lang, ck)\n",
        "        print(f\"[{lang}] done {os.path.basename(fp)} → tokens={tok_count:,}, docs={doc_count:,}, lines={line_count:,}\")\n",
        "\n",
        "    lang_token_counts[lang] = tok_count\n",
        "    grand_total += tok_count\n",
        "    elapsed = time.time() - t0\n",
        "    rate = tok_count / max(1e-6, elapsed)\n",
        "    print(f\"\\n[{lang}] FINAL: tokens={tok_count:,} docs={doc_count:,} lines={line_count:,}  ({int(rate):,} tok/s)\")\n",
        "\n",
        "# -------- summary --------\n",
        "print(\"\\n=== TOKEN COUNTS PER LANGUAGE ===\")\n",
        "for lang, n in lang_token_counts.items():\n",
        "    pct = n / grand_total * 100 if grand_total else 0\n",
        "    print(f\"  {lang}: {n:,} tokens  ({pct:.2f}%)\")\n",
        "print(f\"  TOTAL: {grand_total:,} tokens\")\n",
        "\n",
        "# also save to Drive\n",
        "summary_path = \"/content/drive/MyDrive/LMA_SLM/tokenizer_reports/token_counts_per_lang.json\"\n",
        "os.makedirs(os.path.dirname(summary_path), exist_ok=True)\n",
        "with open(summary_path, \"w\") as f:\n",
        "    json.dump({\"per_lang\": lang_token_counts, \"total\": grand_total}, f, indent=2)\n",
        "print(f\"\\n[saved] {summary_path}\")\n",
        "# ============================================================================================================="
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj9XxVWrWztV",
        "outputId": "b77160dd-86e6-41c2-834f-823136db1542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[load] SentencePiece model: /content/drive/MyDrive/LMA_SLM/tokenizers/sp_unigram_64000.model\n",
            "[copy:eng] /content/drive/MyDrive/LMA_SLM/data/splits/eng/val.jsonl -> /content/token_count_local/eng/val.jsonl\n",
            "[copy:eng] /content/drive/MyDrive/LMA_SLM/data/splits/eng/train.jsonl -> /content/token_count_local/eng/train.jsonl\n",
            "[copy:eng] /content/drive/MyDrive/LMA_SLM/data/raw/eng.jsonl -> /content/token_count_local/eng/eng.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jt1VdrbVYGaW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}